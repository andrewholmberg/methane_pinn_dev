{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7071067811865476, 0.7071067811865476)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import imageio\n",
    "from PINN import PINN\n",
    "from Net import Net\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import sklearn.mixture as mixture\n",
    "from unit_conversion import convert_wind\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"{os.getcwd()}/pinn_test_data\"\n",
    "# load in data\n",
    "df_wind_ch4 = pd.read_csv(data_dir + \"/wind_ch4.csv\")\n",
    "df_true_emission = pd.read_csv(data_dir + \"/selected_controll_release.csv\")\n",
    "source_points = np.load(data_dir + \"/source_points.npy\") # shape=(n_source, 3)\n",
    "sensor_points = np.load(data_dir + \"/sensor_points.npy\") # shape=(n_sensor, 3)\n",
    "#col_points = np.load(data_dir + \"/col_points.npy\")  # shape=(n_col, 3)\n",
    "df_bounds = pd.read_csv(data_dir + \"/bounds.csv\", dtype='float32')\n",
    "x_min = df_bounds['x_min'][0]\n",
    "x_max = df_bounds['x_max'][0]\n",
    "y_min = df_bounds['y_min'][0]\n",
    "y_max = df_bounds['y_max'][0]\n",
    "z_min = df_bounds['z_min'][0]\n",
    "z_max = df_bounds['z_max'][0]\n",
    "active_source_idx = 3\n",
    "# x_max = 1\n",
    "# y_max = 1\n",
    "# z_max = 1\n",
    "tfinal = 5*60.\n",
    "source_location = source_points\n",
    "\n",
    "ws = df_wind_ch4['wind_speed.m/s'].to_numpy() # shape=(N_t,)\n",
    "wd = df_wind_ch4['wind_direction'].to_numpy() # shape=(N_t,)\n",
    "df_wind_ch4['x'], df_wind_ch4['y'] = convert_wind(ws,wd)\n",
    "time_dict = dict(zip(df_wind_ch4.index,zip(df_wind_ch4.x,df_wind_ch4.y)))\n",
    "\n",
    "wind_function_x = interp1d(df_wind_ch4.index*60,df_wind_ch4.x)\n",
    "wind_function_y = interp1d(df_wind_ch4.index*60,df_wind_ch4.y)\n",
    "\n",
    "ch4 = np.transpose(df_wind_ch4.iloc[:, 3:].to_numpy()) # shape=(N_obs, N_t)\n",
    "sensor_names = df_wind_ch4.columns[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.01666667 0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andyh\\Documents\\Mines\\Methane Project\\methane_pinn_dev\\Net.py:12: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(m.weight)\n"
     ]
    }
   ],
   "source": [
    "sigma=1\n",
    "model = PINN([100,100,100])\n",
    "source_vals = np.array([1/60 if i ==active_source_idx else 0 for i in range(len(source_location))])\n",
    "print(source_vals)\n",
    "model.set_location(source_location,[tfinal,x_max,y_max,z_max],source_values=source_vals,sigma=sigma,kappa=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[61.84826691, 40.32822479,  4.5       ],\n",
       "       [99.10094831, 54.69940709,  2.        ],\n",
       "       [99.89962676, 24.72759871,  2.        ],\n",
       "       [23.54499552, 57.03946784,  2.        ],\n",
       "       [25.09781584, 22.62636785,  2.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.net.parameters(), lr=1e-4)\n",
    "# from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "# scheduler = ExponentialLR(optimizer, gamma=0.999)  # Decay LR by 5% every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1.583e+08, grad_norm: 0.000e+00, pde_res: 1.352e+03, time: 2.696e-02\n",
      "epoch: 100, loss: 3.663e+04, grad_norm: 0.000e+00, pde_res: 5.601e+03, time: 1.901e-02\n",
      "epoch: 200, loss: 6.428e+03, grad_norm: 0.000e+00, pde_res: 4.304e+03, time: 1.900e-02\n",
      "epoch: 300, loss: 6.498e+03, grad_norm: 0.000e+00, pde_res: 2.563e+03, time: 1.901e-02\n",
      "epoch: 400, loss: 2.237e+03, grad_norm: 0.000e+00, pde_res: 2.237e+03, time: 1.900e-02\n",
      "epoch: 500, loss: 2.115e+03, grad_norm: 0.000e+00, pde_res: 2.115e+03, time: 2.000e-02\n",
      "epoch: 600, loss: 1.659e+03, grad_norm: 0.000e+00, pde_res: 1.659e+03, time: 1.900e-02\n",
      "epoch: 700, loss: 1.780e+03, grad_norm: 0.000e+00, pde_res: 1.780e+03, time: 1.900e-02\n",
      "epoch: 800, loss: 1.831e+03, grad_norm: 0.000e+00, pde_res: 1.831e+03, time: 1.900e-02\n",
      "epoch: 900, loss: 1.620e+03, grad_norm: 0.000e+00, pde_res: 1.620e+03, time: 2.000e-02\n",
      "epoch: 1000, loss: 1.904e+03, grad_norm: 0.000e+00, pde_res: 1.904e+03, time: 2.000e-02\n",
      "epoch: 1100, loss: 1.724e+03, grad_norm: 0.000e+00, pde_res: 1.724e+03, time: 2.000e-02\n",
      "epoch: 1200, loss: 1.783e+03, grad_norm: 0.000e+00, pde_res: 1.783e+03, time: 1.943e-02\n",
      "epoch: 1300, loss: 1.299e+03, grad_norm: 0.000e+00, pde_res: 1.299e+03, time: 1.900e-02\n",
      "epoch: 1400, loss: 1.769e+03, grad_norm: 0.000e+00, pde_res: 1.769e+03, time: 2.051e-02\n",
      "epoch: 1500, loss: 1.473e+03, grad_norm: 0.000e+00, pde_res: 1.473e+03, time: 1.900e-02\n",
      "epoch: 1600, loss: 1.666e+03, grad_norm: 0.000e+00, pde_res: 1.666e+03, time: 2.100e-02\n",
      "epoch: 1700, loss: 1.583e+03, grad_norm: 0.000e+00, pde_res: 1.577e+03, time: 2.300e-02\n",
      "epoch: 1800, loss: 1.255e+03, grad_norm: 0.000e+00, pde_res: 1.255e+03, time: 2.000e-02\n",
      "epoch: 1900, loss: 1.511e+03, grad_norm: 0.000e+00, pde_res: 1.511e+03, time: 1.801e-02\n",
      "epoch: 2000, loss: 1.120e+03, grad_norm: 0.000e+00, pde_res: 1.120e+03, time: 2.000e-02\n",
      "epoch: 2100, loss: 1.522e+03, grad_norm: 0.000e+00, pde_res: 1.522e+03, time: 1.901e-02\n",
      "epoch: 2200, loss: 1.405e+03, grad_norm: 0.000e+00, pde_res: 1.405e+03, time: 1.900e-02\n",
      "epoch: 2300, loss: 1.336e+03, grad_norm: 0.000e+00, pde_res: 1.336e+03, time: 2.201e-02\n",
      "epoch: 2400, loss: 8.459e+02, grad_norm: 0.000e+00, pde_res: 8.459e+02, time: 1.928e-02\n",
      "epoch: 2500, loss: 1.027e+03, grad_norm: 0.000e+00, pde_res: 1.027e+03, time: 1.901e-02\n",
      "epoch: 2600, loss: 1.388e+03, grad_norm: 0.000e+00, pde_res: 1.388e+03, time: 1.900e-02\n",
      "epoch: 2700, loss: 9.369e+02, grad_norm: 0.000e+00, pde_res: 9.369e+02, time: 1.900e-02\n",
      "epoch: 2800, loss: 9.853e+02, grad_norm: 0.000e+00, pde_res: 9.853e+02, time: 1.901e-02\n",
      "epoch: 2900, loss: 1.805e+03, grad_norm: 0.000e+00, pde_res: 1.805e+03, time: 1.900e-02\n",
      "epoch: 3000, loss: 1.225e+03, grad_norm: 0.000e+00, pde_res: 1.225e+03, time: 1.900e-02\n",
      "epoch: 3100, loss: 9.861e+02, grad_norm: 0.000e+00, pde_res: 9.861e+02, time: 2.001e-02\n",
      "epoch: 3200, loss: 9.868e+02, grad_norm: 0.000e+00, pde_res: 9.868e+02, time: 2.201e-02\n",
      "epoch: 3300, loss: 9.900e+02, grad_norm: 0.000e+00, pde_res: 9.900e+02, time: 2.000e-02\n",
      "epoch: 3400, loss: 6.911e+02, grad_norm: 0.000e+00, pde_res: 6.911e+02, time: 1.949e-02\n",
      "epoch: 3500, loss: 7.886e+02, grad_norm: 0.000e+00, pde_res: 7.886e+02, time: 1.900e-02\n",
      "epoch: 3600, loss: 8.300e+02, grad_norm: 0.000e+00, pde_res: 8.300e+02, time: 2.000e-02\n",
      "epoch: 3700, loss: 1.348e+03, grad_norm: 0.000e+00, pde_res: 1.348e+03, time: 2.000e-02\n",
      "epoch: 3800, loss: 9.757e+02, grad_norm: 0.000e+00, pde_res: 9.757e+02, time: 2.000e-02\n",
      "epoch: 3900, loss: 1.049e+03, grad_norm: 0.000e+00, pde_res: 1.049e+03, time: 1.900e-02\n",
      "epoch: 4000, loss: 6.855e+02, grad_norm: 0.000e+00, pde_res: 6.855e+02, time: 2.601e-02\n",
      "epoch: 4100, loss: 7.795e+02, grad_norm: 0.000e+00, pde_res: 7.795e+02, time: 2.001e-02\n",
      "epoch: 4200, loss: 7.618e+02, grad_norm: 0.000e+00, pde_res: 7.618e+02, time: 1.851e-02\n",
      "epoch: 4300, loss: 8.667e+02, grad_norm: 0.000e+00, pde_res: 8.667e+02, time: 1.900e-02\n",
      "epoch: 4400, loss: 7.854e+02, grad_norm: 0.000e+00, pde_res: 7.854e+02, time: 2.000e-02\n",
      "epoch: 4500, loss: 5.080e+02, grad_norm: 0.000e+00, pde_res: 5.080e+02, time: 1.901e-02\n",
      "epoch: 4600, loss: 6.747e+02, grad_norm: 0.000e+00, pde_res: 6.747e+02, time: 2.000e-02\n",
      "epoch: 4700, loss: 9.196e+02, grad_norm: 0.000e+00, pde_res: 9.196e+02, time: 1.951e-02\n",
      "epoch: 4800, loss: 8.253e+02, grad_norm: 0.000e+00, pde_res: 8.253e+02, time: 2.000e-02\n",
      "epoch: 4900, loss: 6.687e+02, grad_norm: 0.000e+00, pde_res: 6.687e+02, time: 1.951e-02\n",
      "epoch: 5000, loss: 8.669e+02, grad_norm: 0.000e+00, pde_res: 8.669e+02, time: 2.000e-02\n",
      "epoch: 5100, loss: 7.093e+02, grad_norm: 0.000e+00, pde_res: 7.093e+02, time: 2.001e-02\n",
      "epoch: 5200, loss: 8.744e+02, grad_norm: 0.000e+00, pde_res: 8.744e+02, time: 2.000e-02\n",
      "epoch: 5300, loss: 5.847e+02, grad_norm: 0.000e+00, pde_res: 5.847e+02, time: 1.900e-02\n",
      "epoch: 5400, loss: 5.537e+02, grad_norm: 0.000e+00, pde_res: 5.537e+02, time: 1.980e-02\n",
      "epoch: 5500, loss: 5.383e+02, grad_norm: 0.000e+00, pde_res: 5.383e+02, time: 1.951e-02\n",
      "epoch: 5600, loss: 5.960e+02, grad_norm: 0.000e+00, pde_res: 5.960e+02, time: 2.000e-02\n",
      "epoch: 5700, loss: 6.393e+02, grad_norm: 0.000e+00, pde_res: 6.393e+02, time: 2.051e-02\n",
      "epoch: 5800, loss: 5.785e+02, grad_norm: 0.000e+00, pde_res: 5.785e+02, time: 1.901e-02\n",
      "epoch: 5900, loss: 6.052e+02, grad_norm: 0.000e+00, pde_res: 6.052e+02, time: 2.051e-02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 40\u001b[0m\n\u001b[0;32m     36\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_1 \u001b[38;5;241m+\u001b[39m loss_2 \u001b[38;5;241m+\u001b[39m loss_3\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# loss = loss_1+loss_2+loss_3\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# compute norm of gradient of the network\u001b[39;00m\n\u001b[0;32m     43\u001b[0m grad_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\andyh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\andyh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\andyh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n= int(5e1)\n",
    "# n=1\n",
    "icn = int(1e1)\n",
    "sn = int(5e1)\n",
    "best_loss = np.inf\n",
    "max_epochs = int(2e4)\n",
    "print_freq = 100\n",
    "\n",
    "sampling_freq = 10 # how often to resample collocation and source points\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if epoch % sampling_freq == 0:\n",
    "\n",
    "        source_collocation_points = model.source_points(sn,sigma*2) \n",
    "        ic_col = torch.cat([torch.zeros(icn,1), torch.rand(icn,1)*x_max, torch.rand(icn,1)*y_max, torch.rand(icn,1)*z_max], dim=1)\n",
    "        collocation_points = torch.cat([torch.rand(n,1)*tfinal, torch.rand(n,1)*x_max*2 - x_max*.5, torch.rand(n,1)*y_max*2- y_max*.5, torch.rand(n,1)*z_max*2 - z_max*.5], dim=1)\n",
    "        # collocation_points = torch.cat([collocation_points,ic_col,source_collocation_points])\n",
    "        collocation_points = torch.cat([collocation_points,source_collocation_points,ic_col])\n",
    "        collocation_points.requires_grad_(True)\n",
    "        # t = np.floor(collocation_points[:,0:1].detach().numpy().flatten())\n",
    "        # uv = torch.tensor([time_dict[t[i]] for i in range(len(t))])\n",
    "        # uv = torch.ones(len(collocation_points),2)*10#wind tensor\n",
    "        wind_tensor = torch.cat([torch.tensor(wind_function_x(collocation_points[:,0:1].detach().cpu().numpy())),torch.tensor(wind_function_y(collocation_points[:,0:1].detach().cpu().numpy()))],dim=1)\n",
    "        # uv[:,1:]*= -1\n",
    "        # print(uv)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss_1 ,pde_1 = model.compute_pde_loss(collocation_points,wind_tensor) # PDE residual loss\n",
    "    loss_2 = model.compute_negative_loss(collocation_points)\n",
    "    loss_3 = model.compute_data_loss(torch.cat([torch.zeros(collocation_points.shape[0],1),collocation_points[:,1:]],dim=1),torch.zeros(collocation_points.shape[0],1))\n",
    "    # loss = loss_1+loss_2+loss_3\n",
    "    # loss = loss_3\n",
    "    loss = loss_1 + loss_2 + loss_3\n",
    "\n",
    "    # loss = loss_1+loss_2+loss_3\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # compute norm of gradient of the network\n",
    "    grad_norm = 0\n",
    "    # for p in model.net.parameters():\n",
    "    #     grad_norm += p.grad.data.norm(2).item()**2\n",
    "    # grad_norm = grad_norm**0.5\n",
    "\n",
    "\n",
    "    if loss.item() < best_loss:\n",
    "        torch.save(model,'best_mod.m')\n",
    "    optimizer.step()\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    # scheduler.step()\n",
    "\n",
    "    if epoch % print_freq == 0:\n",
    "\n",
    "        print('epoch: %d, loss: %1.3e, grad_norm: %1.3e, pde_res: %1.3e, time: %1.3e' % (epoch, loss.item(), grad_norm, loss_1.item(), epoch_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 45.8859,  23.6930,  57.9901,   5.5582],\n",
       "        [203.6488,  23.3892,  56.1385,   1.9355],\n",
       "        [152.3492,  23.2402,  56.0816,   2.4387],\n",
       "        ...,\n",
       "        [110.2668,  25.1099,  58.6581,   2.1268],\n",
       "        [176.3741,  24.8293,  56.3677,   4.3704],\n",
       "        [ 89.8052,  25.3906,  57.1973,   2.7015]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_collocation_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('best_mod.m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load the best model \n",
    "Z_value = source_location[active_source_idx,2]\n",
    "# net.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Define the grid and time steps\n",
    "n= 100\n",
    "x_grid = np.linspace(0, x_max, n)\n",
    "y_grid = np.linspace(0, y_max, n)\n",
    "z_grid = np.linspace(0, z_max, n)\n",
    "\n",
    "X, Y, = np.meshgrid(x_grid, y_grid)\n",
    "Z= X * 0 + Z_value\n",
    "\n",
    "grid_points = np.vstack([X.ravel(), Y.ravel(), Z.ravel()]).T\n",
    "# grid_points = np.vstack([X.ravel(), Y.ravel(), Z.ravel()]).T  # Flatten the grid\n",
    "grid_points = torch.tensor(grid_points, dtype=torch.float32)\n",
    "\n",
    "time_steps = np.linspace(0, tfinal, 20)  # 10 time steps from 0 to 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andyh\\AppData\\Local\\Temp\\ipykernel_15632\\747668458.py:22: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images.append(imageio.imread(f\"concentration_t_{t:.2f}.png\"))  # Append the image to the list\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# save as a GIF\n",
    "import imageio\n",
    "import os\n",
    "\n",
    "images = []\n",
    "# source_loc = torch.tensor([[.5,.5,.5]])\n",
    "source_loc = model.source_locs\n",
    "for t in time_steps:\n",
    "    t_tensor = torch.full((grid_points.shape[0], 1), t, dtype=torch.float32)  # Time input\n",
    "    concentration = model.forward(torch.cat([t_tensor,grid_points],dim=1),scaled=True).cpu().detach().numpy().reshape(100, 100)  # Predict and reshape\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.contourf(X, Y, concentration, levels=50, cmap='viridis', vmin=0, vmax=1000)  # Plot concentration as a contour plot\n",
    "    plt.plot(model.source_locs[active_source_idx,0], model.source_locs[active_source_idx,1], 'ro', label='Source Location')  # Plot the source location\n",
    "    plt.colorbar(label='Concentration')\n",
    "    plt.title(f\"Gas Concentration at t = {t:.2f}\")\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.savefig(f\"concentration_t_{t:.2f}.png\")  # Save the plot as an image\n",
    "    plt.close()\n",
    "    \n",
    "    images.append(imageio.imread(f\"concentration_t_{t:.2f}.png\"))  # Append the image to the list\n",
    "    os.remove(f\"concentration_t_{t:.2f}.png\")  # Remove the image file\n",
    "\n",
    "imageio.mimsave(f'output_gifs/test_site_example{int(time.time())}.gif', images)  # Save the images as a GIF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[61.84826691 40.32822479  4.5       ]\n",
      " [99.10094831 54.69940709  2.        ]\n",
      " [99.89962676 24.72759871  2.        ]\n",
      " [23.54499552 57.03946784  2.        ]\n",
      " [25.09781584 22.62636785  2.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(source_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'time' has no attribute 'datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatetime\u001b[49m())\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'time' has no attribute 'datetime'"
     ]
    }
   ],
   "source": [
    "print(time.datetime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
