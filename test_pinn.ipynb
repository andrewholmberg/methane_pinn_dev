{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PINN import PINN\n",
    "from Net import Net\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "# set default type double\n",
    "default_type = torch.float32\n",
    "torch.set_default_dtype(default_type)\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"{os.getcwd()}/pinn_test_data\"\n",
    "# load in data\n",
    "df_wind_ch4 = pd.read_csv(data_dir + \"/wind_ch4.csv\")\n",
    "df_true_emission = pd.read_csv(data_dir + \"/selected_controll_release.csv\")\n",
    "source_points = np.load(data_dir + \"/source_points.npy\") # shape=(n_source, 3)\n",
    "sensor_points = np.load(data_dir + \"/sensor_points.npy\") # shape=(n_sensor, 3)\n",
    "#col_points = np.load(data_dir + \"/col_points.npy\")  # shape=(n_col, 3)\n",
    "df_bounds = pd.read_csv(data_dir + \"/bounds.csv\", dtype='float32')\n",
    "x_min = df_bounds['x_min'][0]\n",
    "x_max = df_bounds['x_max'][0]\n",
    "y_min = df_bounds['y_min'][0]\n",
    "y_max = df_bounds['y_max'][0]\n",
    "z_min = df_bounds['z_min'][0]\n",
    "z_max = df_bounds['z_max'][0]\n",
    "\n",
    "\n",
    "ws = df_wind_ch4['wind_speed.m/s'].to_numpy() # shape=(N_t,)\n",
    "wd = df_wind_ch4['wind_direction'].to_numpy() # shape=(N_t,)\n",
    "ch4 = np.transpose(df_wind_ch4.iloc[:, 3:].to_numpy()) # shape=(N_obs, N_t)\n",
    "sensor_names = df_wind_ch4.columns[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[61.84826691 40.32822479  4.5       ]\n",
      " [99.10094831 54.69940709  2.        ]\n",
      " [99.89962676 24.72759871  2.        ]\n",
      " [23.54499552 57.03946784  2.        ]\n",
      " [25.09781584 22.62636785  2.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(source_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\andyh\\Documents\\Projects\\mines\\methane_project\\methane_pinn_dev\\Net.py:12: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(m.weight)\n"
     ]
    }
   ],
   "source": [
    "model = PINN([100,100,100])\n",
    "standard_dev = .1\n",
    "tfinal = 4.\n",
    "model.set_location(source_points,[tfinal,x_max,y_max,z_max],source_values=[0,0,0,1,0],sigma = standard_dev)\n",
    "# tfinal = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.net.parameters(), lr=1e-5)\n",
    "# from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "# scheduler = ExponentialLR(optimizer, gamma=0.995)  # Decay LR by 5% every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 2.492e+02, grad_norm: 5.781e+03, pde_res: 2.492e+02, time: 4.045e-01\n",
      "epoch: 100, loss: 1.032e+02, grad_norm: 3.716e+03, pde_res: 1.032e+02, time: 8.826e-03\n",
      "epoch: 200, loss: 3.523e+01, grad_norm: 2.090e+03, pde_res: 3.523e+01, time: 1.031e-02\n",
      "epoch: 300, loss: 1.025e+01, grad_norm: 1.006e+03, pde_res: 1.025e+01, time: 9.158e-03\n",
      "epoch: 400, loss: 3.472e+00, grad_norm: 4.437e+02, pde_res: 3.472e+00, time: 9.001e-03\n",
      "epoch: 500, loss: 1.494e+00, grad_norm: 2.185e+02, pde_res: 1.494e+00, time: 8.668e-03\n",
      "epoch: 600, loss: 8.086e-01, grad_norm: 1.228e+02, pde_res: 8.086e-01, time: 8.550e-03\n",
      "epoch: 700, loss: 5.510e-01, grad_norm: 7.083e+01, pde_res: 5.510e-01, time: 8.933e-03\n",
      "epoch: 800, loss: 4.020e-01, grad_norm: 5.825e+01, pde_res: 4.020e-01, time: 7.906e-03\n",
      "epoch: 900, loss: 3.171e-01, grad_norm: 3.970e+01, pde_res: 3.171e-01, time: 8.724e-03\n",
      "epoch: 1000, loss: 2.632e-01, grad_norm: 2.908e+01, pde_res: 2.632e-01, time: 9.714e-03\n",
      "epoch: 1100, loss: 2.088e-01, grad_norm: 2.171e+01, pde_res: 2.088e-01, time: 8.698e-03\n",
      "epoch: 1200, loss: 1.753e-01, grad_norm: 1.640e+01, pde_res: 1.753e-01, time: 9.324e-03\n",
      "epoch: 1300, loss: 1.521e-01, grad_norm: 1.096e+01, pde_res: 1.521e-01, time: 9.262e-03\n",
      "epoch: 1400, loss: 1.300e-01, grad_norm: 1.125e+01, pde_res: 1.300e-01, time: 8.921e-03\n",
      "epoch: 1500, loss: 1.152e-01, grad_norm: 1.232e+01, pde_res: 1.152e-01, time: 7.970e-03\n",
      "epoch: 1600, loss: 9.628e-02, grad_norm: 7.690e+00, pde_res: 9.628e-02, time: 9.432e-03\n",
      "epoch: 1700, loss: 8.753e-02, grad_norm: 7.778e+00, pde_res: 8.753e-02, time: 8.960e-03\n",
      "epoch: 1800, loss: 7.826e-02, grad_norm: 7.225e+00, pde_res: 7.826e-02, time: 1.196e-02\n",
      "epoch: 1900, loss: 6.719e-02, grad_norm: 5.997e+00, pde_res: 6.719e-02, time: 9.305e-03\n",
      "epoch: 2000, loss: 5.974e-02, grad_norm: 6.585e+00, pde_res: 5.974e-02, time: 8.543e-03\n",
      "epoch: 2100, loss: 5.547e-02, grad_norm: 6.340e+00, pde_res: 5.547e-02, time: 8.781e-03\n",
      "epoch: 2200, loss: 5.198e-02, grad_norm: 3.526e+00, pde_res: 5.198e-02, time: 9.914e-03\n",
      "epoch: 2300, loss: 4.532e-02, grad_norm: 5.526e+00, pde_res: 4.532e-02, time: 8.884e-03\n",
      "epoch: 2400, loss: 4.353e-02, grad_norm: 4.577e+00, pde_res: 4.353e-02, time: 9.077e-03\n",
      "epoch: 2500, loss: 4.129e-02, grad_norm: 3.027e+00, pde_res: 4.129e-02, time: 8.546e-03\n",
      "epoch: 2600, loss: 3.919e-02, grad_norm: 2.402e+00, pde_res: 3.919e-02, time: 1.019e-02\n",
      "epoch: 2700, loss: 3.419e-02, grad_norm: 2.129e+00, pde_res: 3.419e-02, time: 9.673e-03\n",
      "epoch: 2800, loss: 3.305e-02, grad_norm: 5.978e+00, pde_res: 3.305e-02, time: 8.780e-03\n",
      "epoch: 2900, loss: 3.262e-02, grad_norm: 1.818e+00, pde_res: 3.262e-02, time: 9.777e-03\n",
      "epoch: 3000, loss: 2.976e-02, grad_norm: 4.755e+00, pde_res: 2.976e-02, time: 9.230e-03\n",
      "epoch: 3100, loss: 2.881e-02, grad_norm: 6.418e+00, pde_res: 2.881e-02, time: 8.970e-03\n",
      "epoch: 3200, loss: 2.569e-02, grad_norm: 1.233e+00, pde_res: 2.569e-02, time: 8.235e-03\n",
      "epoch: 3300, loss: 2.302e-02, grad_norm: 1.584e+00, pde_res: 2.302e-02, time: 8.934e-03\n",
      "epoch: 3400, loss: 2.332e-02, grad_norm: 1.606e+00, pde_res: 2.332e-02, time: 8.878e-03\n",
      "epoch: 3500, loss: 2.243e-02, grad_norm: 2.570e+00, pde_res: 2.243e-02, time: 8.523e-03\n",
      "epoch: 3600, loss: 2.094e-02, grad_norm: 5.587e+00, pde_res: 2.094e-02, time: 1.041e-02\n",
      "epoch: 3700, loss: 2.113e-02, grad_norm: 9.483e-01, pde_res: 2.113e-02, time: 9.681e-03\n",
      "epoch: 3800, loss: 2.111e-02, grad_norm: 1.299e+00, pde_res: 2.111e-02, time: 8.737e-03\n",
      "epoch: 3900, loss: 1.811e-02, grad_norm: 1.093e+00, pde_res: 1.811e-02, time: 8.793e-03\n",
      "epoch: 4000, loss: 1.646e-02, grad_norm: 8.010e-01, pde_res: 1.646e-02, time: 8.887e-03\n",
      "epoch: 4100, loss: 1.775e-02, grad_norm: 2.949e+00, pde_res: 1.775e-02, time: 8.249e-03\n",
      "epoch: 4200, loss: 1.567e-02, grad_norm: 1.208e+00, pde_res: 1.567e-02, time: 8.879e-03\n",
      "epoch: 4300, loss: 1.565e-02, grad_norm: 3.505e+00, pde_res: 1.565e-02, time: 1.071e-02\n",
      "epoch: 4400, loss: 1.477e-02, grad_norm: 2.654e+00, pde_res: 1.477e-02, time: 9.827e-03\n",
      "epoch: 4500, loss: 1.422e-02, grad_norm: 2.333e+00, pde_res: 1.422e-02, time: 8.027e-03\n",
      "epoch: 4600, loss: 1.312e-02, grad_norm: 1.853e+00, pde_res: 1.312e-02, time: 1.002e-02\n",
      "epoch: 4700, loss: 1.328e-02, grad_norm: 2.042e+00, pde_res: 1.328e-02, time: 9.670e-03\n",
      "epoch: 4800, loss: 1.246e-02, grad_norm: 2.504e+00, pde_res: 1.246e-02, time: 8.931e-03\n",
      "epoch: 4900, loss: 1.269e-02, grad_norm: 4.641e-01, pde_res: 1.269e-02, time: 8.994e-03\n",
      "epoch: 5000, loss: 1.150e-02, grad_norm: 1.237e+00, pde_res: 1.150e-02, time: 1.037e-02\n",
      "epoch: 5100, loss: 1.103e-02, grad_norm: 3.077e+00, pde_res: 1.103e-02, time: 8.728e-03\n",
      "epoch: 5200, loss: 1.124e-02, grad_norm: 4.461e-01, pde_res: 1.124e-02, time: 9.533e-03\n",
      "epoch: 5300, loss: 1.080e-02, grad_norm: 3.915e-01, pde_res: 1.080e-02, time: 1.009e-02\n",
      "epoch: 5400, loss: 9.593e-03, grad_norm: 1.854e+00, pde_res: 9.593e-03, time: 8.122e-03\n",
      "epoch: 5500, loss: 9.466e-03, grad_norm: 5.486e-01, pde_res: 9.466e-03, time: 9.919e-03\n",
      "epoch: 5600, loss: 9.254e-03, grad_norm: 2.749e+00, pde_res: 9.254e-03, time: 1.015e-02\n",
      "epoch: 5700, loss: 9.706e-03, grad_norm: 6.965e-01, pde_res: 9.706e-03, time: 1.023e-02\n",
      "epoch: 5800, loss: 7.877e-03, grad_norm: 3.637e-01, pde_res: 7.877e-03, time: 9.507e-03\n",
      "epoch: 5900, loss: 8.346e-03, grad_norm: 2.795e+00, pde_res: 8.346e-03, time: 9.212e-03\n",
      "epoch: 6000, loss: 8.194e-03, grad_norm: 6.971e-01, pde_res: 8.194e-03, time: 8.646e-03\n",
      "epoch: 6100, loss: 8.334e-03, grad_norm: 6.812e-01, pde_res: 8.334e-03, time: 9.342e-03\n",
      "epoch: 6200, loss: 8.254e-03, grad_norm: 3.243e+00, pde_res: 8.254e-03, time: 8.802e-03\n",
      "epoch: 6300, loss: 7.202e-03, grad_norm: 3.090e-01, pde_res: 7.202e-03, time: 9.263e-03\n",
      "epoch: 6400, loss: 7.375e-03, grad_norm: 3.460e-01, pde_res: 7.375e-03, time: 8.701e-03\n",
      "epoch: 6500, loss: 7.944e-03, grad_norm: 6.638e-01, pde_res: 7.944e-03, time: 8.838e-03\n",
      "epoch: 6600, loss: 7.737e-03, grad_norm: 3.469e+00, pde_res: 7.737e-03, time: 1.000e-02\n",
      "epoch: 6700, loss: 7.016e-03, grad_norm: 1.416e+00, pde_res: 7.016e-03, time: 1.101e-02\n",
      "epoch: 6800, loss: 6.755e-03, grad_norm: 1.528e+00, pde_res: 6.755e-03, time: 9.479e-03\n",
      "epoch: 6900, loss: 7.322e-03, grad_norm: 4.775e-01, pde_res: 7.322e-03, time: 9.264e-03\n",
      "epoch: 7000, loss: 6.256e-03, grad_norm: 5.792e-01, pde_res: 6.256e-03, time: 9.505e-03\n",
      "epoch: 7100, loss: 6.519e-03, grad_norm: 1.524e+00, pde_res: 6.519e-03, time: 8.750e-03\n",
      "epoch: 7200, loss: 6.254e-03, grad_norm: 1.943e+00, pde_res: 6.254e-03, time: 9.720e-03\n",
      "epoch: 7300, loss: 5.933e-03, grad_norm: 2.625e-01, pde_res: 5.933e-03, time: 8.751e-03\n",
      "epoch: 7400, loss: 5.994e-03, grad_norm: 1.297e+00, pde_res: 5.994e-03, time: 1.006e-02\n",
      "epoch: 7500, loss: 6.366e-03, grad_norm: 5.581e-01, pde_res: 6.366e-03, time: 8.350e-03\n",
      "epoch: 7600, loss: 5.868e-03, grad_norm: 3.343e-01, pde_res: 5.868e-03, time: 8.806e-03\n",
      "epoch: 7700, loss: 5.337e-03, grad_norm: 6.252e-01, pde_res: 5.337e-03, time: 9.070e-03\n",
      "epoch: 7800, loss: 5.097e-03, grad_norm: 6.524e-01, pde_res: 5.097e-03, time: 9.354e-03\n",
      "epoch: 7900, loss: 5.140e-03, grad_norm: 4.527e-01, pde_res: 5.140e-03, time: 8.756e-03\n",
      "epoch: 8000, loss: 4.686e-03, grad_norm: 1.300e+00, pde_res: 4.686e-03, time: 8.229e-03\n",
      "epoch: 8100, loss: 5.440e-03, grad_norm: 4.927e-01, pde_res: 5.440e-03, time: 8.775e-03\n",
      "epoch: 8200, loss: 4.623e-03, grad_norm: 6.356e-01, pde_res: 4.623e-03, time: 7.978e-03\n",
      "epoch: 8300, loss: 4.979e-03, grad_norm: 4.661e-01, pde_res: 4.979e-03, time: 9.031e-03\n",
      "epoch: 8400, loss: 5.091e-03, grad_norm: 2.492e-01, pde_res: 5.091e-03, time: 9.054e-03\n",
      "epoch: 8500, loss: 4.324e-03, grad_norm: 4.375e-01, pde_res: 4.324e-03, time: 9.875e-03\n",
      "epoch: 8600, loss: 5.057e-03, grad_norm: 6.319e-01, pde_res: 5.057e-03, time: 1.035e-02\n",
      "epoch: 8700, loss: 4.737e-03, grad_norm: 9.829e-01, pde_res: 4.737e-03, time: 9.385e-03\n",
      "epoch: 8800, loss: 5.340e-03, grad_norm: 4.576e-01, pde_res: 5.340e-03, time: 1.032e-02\n",
      "epoch: 8900, loss: 4.767e-03, grad_norm: 1.062e+00, pde_res: 4.767e-03, time: 9.232e-03\n",
      "epoch: 9000, loss: 5.762e-03, grad_norm: 1.110e+00, pde_res: 5.762e-03, time: 9.875e-03\n",
      "epoch: 9100, loss: 4.495e-03, grad_norm: 8.247e-01, pde_res: 4.495e-03, time: 9.233e-03\n",
      "epoch: 9200, loss: 4.278e-03, grad_norm: 8.030e-01, pde_res: 4.278e-03, time: 1.002e-02\n",
      "epoch: 9300, loss: 4.495e-03, grad_norm: 6.424e-01, pde_res: 4.495e-03, time: 9.961e-03\n",
      "epoch: 9400, loss: 3.926e-03, grad_norm: 1.580e+00, pde_res: 3.926e-03, time: 9.196e-03\n",
      "epoch: 9500, loss: 3.723e-03, grad_norm: 8.041e-01, pde_res: 3.723e-03, time: 9.343e-03\n",
      "epoch: 9600, loss: 3.970e-03, grad_norm: 6.054e-01, pde_res: 3.970e-03, time: 9.079e-03\n",
      "epoch: 9700, loss: 4.184e-03, grad_norm: 7.145e-01, pde_res: 4.184e-03, time: 9.881e-03\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m sample_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 15\u001b[0m     source_collocation_points \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_source_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstandard_dev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# ic_col = torch.cat([torch.rand(sn,1)*tfinal*.1, torch.rand(sn,1)*x_max, torch.rand(sn,1)*y_max, torch.rand(sn,1)*z_max], dim=1)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     collocation_points \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([torch\u001b[38;5;241m.\u001b[39mrand(n,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mtfinal, torch\u001b[38;5;241m.\u001b[39mrand(n,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mx_max, torch\u001b[38;5;241m.\u001b[39mrand(n,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39my_max, torch\u001b[38;5;241m.\u001b[39mrand(n,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mz_max], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32md:\\andyh\\Documents\\Projects\\mines\\methane_project\\methane_pinn_dev\\PINN.py:60\u001b[0m, in \u001b[0;36mPINN.source_points\u001b[1;34m(self, n, sigma)\u001b[0m\n\u001b[0;32m     58\u001b[0m source_stacked \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39mtile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_locs[i],(n,\u001b[38;5;241m1\u001b[39m)))\n\u001b[0;32m     59\u001b[0m diff \u001b[38;5;241m=\u001b[39m rand_source \u001b[38;5;241m-\u001b[39m source_stacked  \u001b[38;5;66;03m# Shape: (n, m, d)\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m squared_distances \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(\u001b[43mdiff\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)    \u001b[38;5;66;03m# Shape: (n, m)\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Compute Gaussian source term\u001b[39;00m\n\u001b[0;32m     62\u001b[0m source_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq[i] \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39msquared_distances \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m sigma\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Shape: (n, m)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andyh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:34\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m(f):\n\u001b[0;32m     32\u001b[0m     assigned \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mWRAPPER_ASSIGNMENTS\n\u001b[1;32m---> 34\u001b[0m     \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f, assigned\u001b[38;5;241m=\u001b[39massigned)\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m             \u001b[38;5;66;03m# See https://github.com/pytorch/pytorch/issues/75462\u001b[39;00m\n\u001b[0;32m     38\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sampling_methods import spread_sample_source\n",
    "n= int(3e3)\n",
    "sn = int(5e3)\n",
    "best_loss = np.inf\n",
    "print_freq = 100\n",
    "max_epochs = int(2e4)\n",
    "sample_freq = 5\n",
    "cycle_freq = 50\n",
    "n_source_samples = int(8e2)\n",
    "\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    start_time = time.time()\n",
    "    if epoch % sample_freq == 0:\n",
    "        source_collocation_points = model.source_points(n_source_samples,standard_dev)\n",
    "        # ic_col = torch.cat([torch.rand(sn,1)*tfinal*.1, torch.rand(sn,1)*x_max, torch.rand(sn,1)*y_max, torch.rand(sn,1)*z_max], dim=1)\n",
    "        collocation_points = torch.cat([torch.rand(n,1)*tfinal, torch.rand(n,1)*x_max, torch.rand(n,1)*y_max, torch.rand(n,1)*z_max], dim=1)\n",
    "        # collocation_points = torch.empty(0,4)\n",
    "        # ic_col = torch.empty(0,4)\n",
    "        # ic_col.requires_grad_()\n",
    "        # gradual_collocation_points = torch.tensor(spread_sample_source(source_points,[0,1,0,0,0],[30,30,1],50,cycle_freq//sample_freq,(epoch%cycle_freq)//sample_freq,10,10)).float()\n",
    "        gradual_collocation_points = torch.tensor(spread_sample_source(source_points,[0,1,0,0,0],[30,30,1],50,20,20,tfinal,10)).float()\n",
    "\n",
    "        collocation_points = torch.cat([collocation_points,source_collocation_points])\n",
    "        wind_vector = torch.ones(len(collocation_points),2)*2\n",
    "        gradual_wind_vector = torch.ones(len(gradual_collocation_points),2)*2\n",
    "        # wind_vector[:,0] *= -1\n",
    "    optimizer.zero_grad()\n",
    "    ic = torch.cat([torch.zeros(len(collocation_points),1),collocation_points[:,1:]],dim=1)\n",
    "    ic.requires_grad_\n",
    "\n",
    "    loss_3 = torch.sum(model.forward(ic)**2)\n",
    "    loss_1 ,pde_1 = model.compute_pde_loss(collocation_points,wind_vector) # PDE residual loss\n",
    "    loss_2, pde_2 = model.compute_pde_loss(gradual_collocation_points,gradual_wind_vector)\n",
    "    # loss_2,pde_2 = model.loss_function(source_collocation_points, uv_points, source_term = source_values) # source term PDE residual loss \n",
    "    # loss_3 ,pde_3 = model.loss_function(torch.concat([collocation_points,source_collocation_points]),torch.concat([collocation_points,source_collocation_points]))\n",
    "    # loss = loss_1+loss_3*1\n",
    "\n",
    "    loss = loss_1#+loss_2\n",
    "    # loss = loss_3+loss_2\n",
    "    # loss = loss_1\n",
    "    loss.backward()\n",
    "\n",
    "    # compute norm of gradient of the network\n",
    "    grad_norm = 0\n",
    "    for p in model.net.parameters():\n",
    "        # if p.grad.data is not None:\n",
    "        if p.grad is not None:\n",
    "            grad_norm += p.grad.data.norm().item()**2\n",
    "    grad_norm = grad_norm**0.5\n",
    "\n",
    "\n",
    "    if loss.item() < best_loss:\n",
    "        torch.save(model,'best_mod.m')\n",
    "    optimizer.step()\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    # scheduler.step()\n",
    "\n",
    "    if epoch % print_freq == 0:\n",
    "\n",
    "        # print epoch and loss using %1.3e format\n",
    "        print('epoch: %d, loss: %1.3e, grad_norm: %1.3e, pde_res: %1.3e, time: %1.3e' % (epoch, loss.item(), grad_norm, loss_1.item(), epoch_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Plot the concentration over time\\nfor t in time_steps:\\n    t_tensor = torch.full((grid_points.shape[0], 1), t, dtype=torch.float32)  # Time input\\n    concentration = net(grid_points, t_tensor).cpu().detach().numpy().reshape(100, 100)  # Predict and reshape\\n    \\n    plt.figure()\\n    plt.contourf(X, Y, concentration, levels=50, cmap=\\'viridis\\', vmin=0, vmax=10)  # Plot concentration as a contour plot\\n    plt.plot(source_loc[0,0].cpu(), source_loc[0,1].cpu(), \\'ro\\', label=\\'Source Location\\')  # Plot the source location\\n    plt.colorbar(label=\\'Concentration\\')\\n    # fix colorbar from 0 to 1 \\n    # plt.clim(0, 10.0)  # Set colorbar limits\\n    plt.title(f\"Gas Concentration at t = {t:.2f}\")\\n    plt.xlabel(\\'x\\')\\n    plt.ylabel(\\'y\\')\\n    # fix colorbar \\n    # plt.savefig(f\"concentration_t_{t:.2f}.png\")  # Save the plot as an image\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load the best model \n",
    "Z_value = 2\n",
    "# net.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Define the grid and time steps\n",
    "n= 500\n",
    "x_grid = np.linspace(-x_max, 2.0*x_max, n)\n",
    "y_grid = np.linspace(-y_max, 2.0*y_max, n)\n",
    "z_grid = np.linspace(0, 2, n)\n",
    "x_grid = np.linspace(x_min, x_max, n)\n",
    "y_grid = np.linspace(y_min, y_max, n)\n",
    "z_grid = np.linspace(0, 2, n)\n",
    "X, Y, = np.meshgrid(x_grid, y_grid)\n",
    "Z= X * 0 + Z_value\n",
    "\n",
    "grid_points = np.vstack([X.ravel(), Y.ravel(), Z.ravel()]).T\n",
    "# grid_points = np.vstack([X.ravel(), Y.ravel(), Z.ravel()]).T  # Flatten the grid\n",
    "grid_points = torch.tensor(grid_points).float()\n",
    "\n",
    "time_steps = np.linspace(0, tfinal, 10)  # 10 time steps from 0 to 1\n",
    "\n",
    "\n",
    "'''\n",
    "# Plot the concentration over time\n",
    "for t in time_steps:\n",
    "    t_tensor = torch.full((grid_points.shape[0], 1), t, dtype=torch.float32)  # Time input\n",
    "    concentration = net(grid_points, t_tensor).cpu().detach().numpy().reshape(100, 100)  # Predict and reshape\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.contourf(X, Y, concentration, levels=50, cmap='viridis', vmin=0, vmax=10)  # Plot concentration as a contour plot\n",
    "    plt.plot(source_loc[0,0].cpu(), source_loc[0,1].cpu(), 'ro', label='Source Location')  # Plot the source location\n",
    "    plt.colorbar(label='Concentration')\n",
    "    # fix colorbar from 0 to 1 \n",
    "    # plt.clim(0, 10.0)  # Set colorbar limits\n",
    "    plt.title(f\"Gas Concentration at t = {t:.2f}\")\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    # fix colorbar \n",
    "    # plt.savefig(f\"concentration_t_{t:.2f}.png\")  # Save the plot as an image\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andyh\\AppData\\Local\\Temp\\ipykernel_9980\\3240819884.py:23: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images.append(imageio.imread(f\"concentration_t_{t:.2f}.png\"))  # Append the image to the list\n"
     ]
    }
   ],
   "source": [
    "# save as a GIF\n",
    "import imageio\n",
    "import os\n",
    "\n",
    "images = []\n",
    "# source_loc = torch.tensor([[.5,.5,.5]])\n",
    "for t in time_steps:\n",
    "    t_tensor = torch.full((grid_points.shape[0], 1), t).float()  # Time input\n",
    "    concentration = model.forward(torch.cat([t_tensor,grid_points],dim=1),scaled=False).cpu().detach().numpy().reshape(n, n)  # Predict and reshape\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.contourf(X, Y, concentration, levels=50, cmap='viridis', vmin=0, vmax=10)  # Plot concentration as a contour plot\n",
    "    plt.plot(model.source_locs[1,0], model.source_locs[1,1], 'ro', label='Source Location')  # Plot the source location\n",
    "    plt.colorbar(label='Concentration')\n",
    "    # plt.title(f\"Gas Concentration at t = {t:.2f}\")\n",
    "    plt.title(f\"t = {t:.2f}\")\n",
    "\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.savefig(f\"concentration_t_{t:.2f}.png\")  # Save the plot as an image\n",
    "    plt.close()\n",
    "    \n",
    "    images.append(imageio.imread(f\"concentration_t_{t:.2f}.png\"))  # Append the image to the list\n",
    "    os.remove(f\"concentration_t_{t:.2f}.png\")  # Remove the image file\n",
    "\n",
    "imageio.mimsave(f'test_visual.gif', images)  # Save the images as a GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Gaussian_Mixture' object has no attribute 'score_samples'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39msource_mixture\n\u001b[1;32m----> 2\u001b[0m source_term \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39mexp(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_mixture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore_samples\u001b[49m(model\u001b[38;5;241m.\u001b[39msource_locs)))\n\u001b[0;32m      3\u001b[0m source_term\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Gaussian_Mixture' object has no attribute 'score_samples'"
     ]
    }
   ],
   "source": [
    "model.source_mixture\n",
    "source_term = torch.tensor(np.exp(model.source_mixture.score_samples(model.source_locs)))\n",
    "source_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_tensor.device\n",
    "grid_points.device\n",
    "torch.cat([t_tensor,grid_points],dim=1).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(model.source_mixture.weights_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (hidden): ModuleList(\n",
       "    (0): Linear(in_features=4, out_features=100, bias=True)\n",
       "    (1-2): 2 x Linear(in_features=100, out_features=100, bias=True)\n",
       "    (3): Linear(in_features=100, out_features=1, bias=True)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (tanh): Tanh()\n",
       "  (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
