{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import imageio\n",
    "from PINN import PINN\n",
    "from Net import Net\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"{os.getcwd()}/pinn_test_data\"\n",
    "# load in data\n",
    "df_wind_ch4 = pd.read_csv(data_dir + \"/wind_ch4.csv\")\n",
    "df_true_emission = pd.read_csv(data_dir + \"/selected_controll_release.csv\")\n",
    "source_points = np.load(data_dir + \"/source_points.npy\") # shape=(n_source, 3)\n",
    "sensor_points = np.load(data_dir + \"/sensor_points.npy\") # shape=(n_sensor, 3)\n",
    "#col_points = np.load(data_dir + \"/col_points.npy\")  # shape=(n_col, 3)\n",
    "df_bounds = pd.read_csv(data_dir + \"/bounds.csv\", dtype='float32')\n",
    "x_min = df_bounds['x_min'][0]\n",
    "x_max = df_bounds['x_max'][0]\n",
    "y_min = df_bounds['y_min'][0]\n",
    "y_max = df_bounds['y_max'][0]\n",
    "z_min = df_bounds['z_min'][0]\n",
    "z_max = df_bounds['z_max'][0]\n",
    "\n",
    "x_max = 1\n",
    "y_max = 1\n",
    "z_max = 1\n",
    "source_location = np.array([[.5,.5,.5]])\n",
    "\n",
    "ws = df_wind_ch4['wind_speed.m/s'].to_numpy() # shape=(N_t,)\n",
    "wd = df_wind_ch4['wind_direction'].to_numpy() # shape=(N_t,)\n",
    "ch4 = np.transpose(df_wind_ch4.iloc[:, 3:].to_numpy()) # shape=(N_obs, N_t)\n",
    "sensor_names = df_wind_ch4.columns[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PINN([50,50,50])\n",
    "model.set_location(source_location,[1,x_max,y_max,z_max],source_values=[1])\n",
    "tfinal = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.net.parameters(), lr=1e-2)\n",
    "# from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "# scheduler = ExponentialLR(optimizer, gamma=0.999)  # Decay LR by 5% every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 5.616e+01, grad_norm: 3.088e+01, pde_res: 6.264e-02, source_loss: 5.610e+01, time: 1.992e-01\n",
      "epoch: 1, loss: 5.038e+01, grad_norm: 2.648e+01, pde_res: 9.728e-02, source_loss: 5.028e+01, time: 1.353e-01\n",
      "epoch: 2, loss: 4.549e+01, grad_norm: 2.906e+01, pde_res: 4.942e-01, source_loss: 4.500e+01, time: 1.677e-01\n",
      "epoch: 3, loss: 3.973e+01, grad_norm: 3.148e+01, pde_res: 1.570e+00, source_loss: 3.816e+01, time: 1.506e-01\n",
      "epoch: 4, loss: 3.377e+01, grad_norm: 2.791e+01, pde_res: 4.143e+00, source_loss: 2.962e+01, time: 1.440e-01\n",
      "epoch: 5, loss: 2.959e+01, grad_norm: 1.168e+01, pde_res: 9.386e+00, source_loss: 2.020e+01, time: 1.427e-01\n",
      "epoch: 6, loss: 2.985e+01, grad_norm: 1.970e+01, pde_res: 1.765e+01, source_loss: 1.220e+01, time: 1.391e-01\n",
      "epoch: 7, loss: 3.281e+01, grad_norm: 4.564e+01, pde_res: 2.446e+01, source_loss: 8.347e+00, time: 1.336e-01\n",
      "epoch: 8, loss: 3.356e+01, grad_norm: 5.111e+01, pde_res: 2.581e+01, source_loss: 7.753e+00, time: 1.432e-01\n",
      "epoch: 9, loss: 3.211e+01, grad_norm: 4.256e+01, pde_res: 2.342e+01, source_loss: 8.694e+00, time: 1.411e-01\n",
      "epoch: 10, loss: 3.102e+01, grad_norm: 2.525e+01, pde_res: 1.920e+01, source_loss: 1.182e+01, time: 1.335e-01\n",
      "epoch: 11, loss: 2.980e+01, grad_norm: 8.999e+00, pde_res: 1.496e+01, source_loss: 1.484e+01, time: 1.322e-01\n",
      "epoch: 12, loss: 2.960e+01, grad_norm: 6.407e+00, pde_res: 1.137e+01, source_loss: 1.823e+01, time: 1.330e-01\n",
      "epoch: 13, loss: 3.014e+01, grad_norm: 1.676e+01, pde_res: 8.849e+00, source_loss: 2.129e+01, time: 1.441e-01\n",
      "epoch: 14, loss: 3.078e+01, grad_norm: 2.297e+01, pde_res: 7.426e+00, source_loss: 2.335e+01, time: 1.464e-01\n",
      "epoch: 15, loss: 3.107e+01, grad_norm: 2.535e+01, pde_res: 6.945e+00, source_loss: 2.413e+01, time: 1.377e-01\n",
      "epoch: 16, loss: 3.082e+01, grad_norm: 2.425e+01, pde_res: 7.226e+00, source_loss: 2.359e+01, time: 1.482e-01\n",
      "epoch: 17, loss: 3.022e+01, grad_norm: 2.040e+01, pde_res: 8.120e+00, source_loss: 2.210e+01, time: 1.325e-01\n",
      "epoch: 18, loss: 2.955e+01, grad_norm: 1.447e+01, pde_res: 9.490e+00, source_loss: 2.006e+01, time: 1.383e-01\n",
      "epoch: 19, loss: 2.908e+01, grad_norm: 7.424e+00, pde_res: 1.119e+01, source_loss: 1.789e+01, time: 1.308e-01\n",
      "epoch: 20, loss: 2.853e+01, grad_norm: 2.846e+00, pde_res: 1.297e+01, source_loss: 1.556e+01, time: 1.325e-01\n",
      "epoch: 21, loss: 2.853e+01, grad_norm: 8.540e+00, pde_res: 1.462e+01, source_loss: 1.391e+01, time: 1.367e-01\n",
      "epoch: 22, loss: 2.869e+01, grad_norm: 1.337e+01, pde_res: 1.583e+01, source_loss: 1.286e+01, time: 1.418e-01\n",
      "epoch: 23, loss: 2.879e+01, grad_norm: 1.561e+01, pde_res: 1.641e+01, source_loss: 1.238e+01, time: 1.372e-01\n",
      "epoch: 24, loss: 2.870e+01, grad_norm: 1.510e+01, pde_res: 1.630e+01, source_loss: 1.241e+01, time: 1.420e-01\n",
      "epoch: 25, loss: 2.849e+01, grad_norm: 1.211e+01, pde_res: 1.555e+01, source_loss: 1.294e+01, time: 1.308e-01\n",
      "epoch: 26, loss: 2.820e+01, grad_norm: 7.498e+00, pde_res: 1.434e+01, source_loss: 1.386e+01, time: 1.292e-01\n",
      "epoch: 27, loss: 2.802e+01, grad_norm: 4.119e+00, pde_res: 1.288e+01, source_loss: 1.514e+01, time: 1.452e-01\n",
      "epoch: 28, loss: 2.791e+01, grad_norm: 7.747e+00, pde_res: 1.147e+01, source_loss: 1.645e+01, time: 1.359e-01\n",
      "epoch: 29, loss: 2.800e+01, grad_norm: 1.178e+01, pde_res: 1.048e+01, source_loss: 1.752e+01, time: 1.322e-01\n",
      "epoch: 30, loss: 2.883e+01, grad_norm: 1.518e+01, pde_res: 1.009e+01, source_loss: 1.874e+01, time: 1.342e-01\n",
      "epoch: 31, loss: 2.840e+01, grad_norm: 1.356e+01, pde_res: 1.022e+01, source_loss: 1.818e+01, time: 1.331e-01\n",
      "epoch: 32, loss: 2.799e+01, grad_norm: 1.160e+01, pde_res: 1.072e+01, source_loss: 1.727e+01, time: 1.332e-01\n",
      "epoch: 33, loss: 2.773e+01, grad_norm: 9.998e+00, pde_res: 1.137e+01, source_loss: 1.637e+01, time: 1.323e-01\n",
      "epoch: 34, loss: 2.764e+01, grad_norm: 9.015e+00, pde_res: 1.198e+01, source_loss: 1.566e+01, time: 1.301e-01\n",
      "epoch: 35, loss: 2.759e+01, grad_norm: 8.652e+00, pde_res: 1.243e+01, source_loss: 1.517e+01, time: 1.290e-01\n",
      "epoch: 36, loss: 2.747e+01, grad_norm: 7.972e+00, pde_res: 1.256e+01, source_loss: 1.491e+01, time: 1.401e-01\n",
      "epoch: 37, loss: 2.727e+01, grad_norm: 7.215e+00, pde_res: 1.240e+01, source_loss: 1.487e+01, time: 1.288e-01\n",
      "epoch: 38, loss: 2.702e+01, grad_norm: 8.552e+00, pde_res: 1.196e+01, source_loss: 1.506e+01, time: 1.363e-01\n",
      "epoch: 39, loss: 2.664e+01, grad_norm: 1.162e+01, pde_res: 1.141e+01, source_loss: 1.523e+01, time: 1.370e-01\n",
      "epoch: 40, loss: 2.576e+01, grad_norm: 1.270e+01, pde_res: 1.100e+01, source_loss: 1.475e+01, time: 1.342e-01\n",
      "epoch: 41, loss: 2.510e+01, grad_norm: 1.179e+01, pde_res: 1.075e+01, source_loss: 1.435e+01, time: 1.442e-01\n",
      "epoch: 42, loss: 2.414e+01, grad_norm: 1.038e+01, pde_res: 1.071e+01, source_loss: 1.343e+01, time: 1.382e-01\n",
      "epoch: 43, loss: 2.328e+01, grad_norm: 1.263e+01, pde_res: 1.067e+01, source_loss: 1.261e+01, time: 1.282e-01\n",
      "epoch: 44, loss: 2.234e+01, grad_norm: 1.367e+01, pde_res: 1.043e+01, source_loss: 1.191e+01, time: 1.512e-01\n",
      "epoch: 45, loss: 2.151e+01, grad_norm: 1.368e+01, pde_res: 9.761e+00, source_loss: 1.175e+01, time: 1.458e-01\n",
      "epoch: 46, loss: 2.093e+01, grad_norm: 1.334e+01, pde_res: 8.748e+00, source_loss: 1.218e+01, time: 1.585e-01\n",
      "epoch: 47, loss: 2.016e+01, grad_norm: 1.667e+01, pde_res: 8.159e+00, source_loss: 1.200e+01, time: 1.284e-01\n",
      "epoch: 48, loss: 1.879e+01, grad_norm: 1.481e+01, pde_res: 8.366e+00, source_loss: 1.042e+01, time: 1.341e-01\n",
      "epoch: 49, loss: 1.764e+01, grad_norm: 1.352e+01, pde_res: 8.592e+00, source_loss: 9.051e+00, time: 1.415e-01\n",
      "epoch: 50, loss: 1.751e+01, grad_norm: 1.156e+01, pde_res: 8.338e+00, source_loss: 9.172e+00, time: 1.338e-01\n",
      "epoch: 51, loss: 1.688e+01, grad_norm: 1.168e+01, pde_res: 8.248e+00, source_loss: 8.636e+00, time: 1.342e-01\n",
      "epoch: 52, loss: 1.575e+01, grad_norm: 1.109e+01, pde_res: 8.422e+00, source_loss: 7.324e+00, time: 1.332e-01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m loss_1 ,pde_1 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mloss_function(collocation_points,uv) \u001b[38;5;66;03m# PDE residual loss\u001b[39;00m\n\u001b[1;32m     31\u001b[0m loss_2,pde_2 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mloss_function(source_collocation_points, uv_points, source_term \u001b[38;5;241m=\u001b[39m source_values) \u001b[38;5;66;03m# source term PDE residual loss \u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m loss_3 ,pde_3 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcollocation_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43msource_collocation_points\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcollocation_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43msource_collocation_points\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_1 \u001b[38;5;241m+\u001b[39m loss_2\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# loss = loss_2*100\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# loss = loss_1\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# # print loss at first epoch\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# if epoch == 0:\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#     print('epoch: %d, loss: %1.3e, pde_res: %1.3e, source_loss: %1.3e' % (epoch, loss.item(), loss_1.item(), loss_2.item()))\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/Dropbox/2025-PINN-methane/methane_pinn_dev/PINN.py:123\u001b[0m, in \u001b[0;36mPINN.loss_function\u001b[0;34m(self, tx, uv, source_term, scaled)\u001b[0m\n\u001b[1;32m    121\u001b[0m u \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet(tx)\n\u001b[1;32m    122\u001b[0m u_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(outputs\u001b[38;5;241m=\u001b[39mu, inputs\u001b[38;5;241m=\u001b[39mtx, grad_outputs\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones_like(u), create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_unused\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 123\u001b[0m u_xx \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mu_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu_x\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m u\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (batch_size,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# u_t = torch.autograd.grad(outputs=u, inputs=t, grad_outputs=torch.ones_like(u), create_graph=True, retain_graph=True)[0]\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/Dropbox/2025-PINN-methane/methane_pinn_dev/pinn_methane_env/lib/python3.11/site-packages/torch/autograd/__init__.py:496\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    492\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    493\u001b[0m         grad_outputs_\n\u001b[1;32m    494\u001b[0m     )\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    507\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[1;32m    508\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[1;32m    509\u001b[0m     ):\n",
      "File \u001b[0;32m~/Library/CloudStorage/Dropbox/2025-PINN-methane/methane_pinn_dev/pinn_methane_env/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n= int(5e3)\n",
    "sn = 250\n",
    "best_loss = np.inf\n",
    "sigma=.025\n",
    "max_epochs = int(5e2)\n",
    "print_freq = 1\n",
    "\n",
    "sampling_freq = 10 # how often to resample collocation and source points\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if epoch % sampling_freq == 0:\n",
    "        # points for source PDE loss. uvpoints are wind field at different times. source_values is the value of source at source_colloc_points (assumes Gaussian for now)\n",
    "        source_collocation_points,uv_points,source_values = model.source_points(sn,sigma) \n",
    "        # initial condition collocation points with smaller time values 0.1*t_final. \n",
    "        # ic_col = torch.cat([torch.rand(sn,1)*tfinal*.1, torch.rand(sn,1)*x_max, torch.rand(sn,1)*y_max, torch.rand(sn,1)*z_max], dim=1)\n",
    "        collocation_points = torch.cat([torch.rand(n,1)*tfinal, torch.rand(n,1)*x_max, torch.rand(n,1)*y_max, torch.rand(n,1)*z_max], dim=1)\n",
    "\n",
    "        xxx = torch.tensor(model.source_locs).repeat(len(collocation_points),1)\n",
    "        ten = torch.sqrt(torch.sum(torch.square(collocation_points[:,1:] - xxx),axis=1))\n",
    "        collocation_points = collocation_points[ten>sigma*3]\n",
    "    # collocation_points = torch.cat([collocation_points,ic_col])\n",
    "    # collocation_points.requires_grad=True\n",
    "\n",
    "    uv = torch.ones(len(collocation_points),2)*.5\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss_1 ,pde_1 = model.loss_function(collocation_points,uv) # PDE residual loss\n",
    "    loss_2,pde_2 = model.loss_function(source_collocation_points, uv_points, source_term = source_values) # source term PDE residual loss \n",
    "    loss_3 ,pde_3 = model.loss_function(torch.concat([collocation_points,source_collocation_points]),torch.concat([collocation_points,source_collocation_points]))\n",
    "\n",
    "    loss = loss_1 + loss_2\n",
    "    # loss = loss_2*100\n",
    "    # loss = loss_1\n",
    "\n",
    "    # # print loss at first epoch\n",
    "    # if epoch == 0:\n",
    "    #     print('epoch: %d, loss: %1.3e, pde_res: %1.3e, source_loss: %1.3e' % (epoch, loss.item(), loss_1.item(), loss_2.item()))\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # compute norm of gradient of the network\n",
    "    grad_norm = 0\n",
    "    for p in model.net.parameters():\n",
    "        grad_norm += p.grad.data.norm(2).item()**2\n",
    "    grad_norm = grad_norm**0.5\n",
    "\n",
    "\n",
    "    if loss.item() < best_loss:\n",
    "        torch.save(model,'best_mod.m')\n",
    "    optimizer.step()\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    # scheduler.step()\n",
    "\n",
    "    if epoch % print_freq == 0:\n",
    "\n",
    "        # print epoch and loss using %1.3e format\n",
    "        print('epoch: %d, loss: %1.3e, grad_norm: %1.3e, pde_res: %1.3e, source_loss: %1.3e, time: %1.3e' % (epoch, loss.item(), grad_norm, loss_1.item(), loss_2.item(), epoch_time))\n",
    "\n",
    "        # print(epoch, loss.item())\n",
    "        # print(loss_2.item(),loss_1.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('best_mod.m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load the best model \n",
    "Z_value = .5\n",
    "# net.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Define the grid and time steps\n",
    "n= 100\n",
    "x_grid = np.linspace(0, x_max, n)\n",
    "y_grid = np.linspace(0, y_max, n)\n",
    "z_grid = np.linspace(0, z_max, n)\n",
    "\n",
    "X, Y, = np.meshgrid(x_grid, y_grid)\n",
    "Z= X * 0 + Z_value\n",
    "\n",
    "grid_points = np.vstack([X.ravel(), Y.ravel(), Z.ravel()]).T\n",
    "# grid_points = np.vstack([X.ravel(), Y.ravel(), Z.ravel()]).T  # Flatten the grid\n",
    "grid_points = torch.tensor(grid_points, dtype=torch.float32)\n",
    "\n",
    "time_steps = np.linspace(0, tfinal, 20)  # 10 time steps from 0 to 1\n",
    "\n",
    "\n",
    "'''\n",
    "# Plot the concentration over time\n",
    "for t in time_steps:\n",
    "    t_tensor = torch.full((grid_points.shape[0], 1), t, dtype=torch.float32)  # Time input\n",
    "    concentration = net(grid_points, t_tensor).cpu().detach().numpy().reshape(100, 100)  # Predict and reshape\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.contourf(X, Y, concentration, levels=50, cmap='viridis', vmin=0, vmax=10)  # Plot concentration as a contour plot\n",
    "    plt.plot(source_loc[0,0].cpu(), source_loc[0,1].cpu(), 'ro', label='Source Location')  # Plot the source location\n",
    "    plt.colorbar(label='Concentration')\n",
    "    # fix colorbar from 0 to 1 \n",
    "    # plt.clim(0, 10.0)  # Set colorbar limits\n",
    "    plt.title(f\"Gas Concentration at t = {t:.2f}\")\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    # fix colorbar \n",
    "    # plt.savefig(f\"concentration_t_{t:.2f}.png\")  # Save the plot as an image\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as a GIF\n",
    "import imageio\n",
    "import os\n",
    "\n",
    "images = []\n",
    "# source_loc = torch.tensor([[.5,.5,.5]])\n",
    "source_loc = model.source_locs\n",
    "for t in time_steps:\n",
    "    t_tensor = torch.full((grid_points.shape[0], 1), t, dtype=torch.float32)  # Time input\n",
    "    concentration = model.forward(torch.cat([t_tensor,grid_points],dim=1),scaled=True).cpu().detach().numpy().reshape(100, 100)  # Predict and reshape\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.contourf(X, Y, concentration, levels=50, cmap='viridis', vmin=0, vmax=10.0)  # Plot concentration as a contour plot\n",
    "    plt.plot(model.source_locs[0,0], model.source_locs[0,1], 'ro', label='Source Location')  # Plot the source location\n",
    "    plt.colorbar(label='Concentration')\n",
    "    plt.title(f\"Gas Concentration at t = {t:.2f}\")\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.savefig(f\"concentration_t_{t:.2f}.png\")  # Save the plot as an image\n",
    "    plt.close()\n",
    "    \n",
    "    images.append(imageio.imread(f\"concentration_t_{t:.2f}.png\"))  # Append the image to the list\n",
    "    os.remove(f\"concentration_t_{t:.2f}.png\")  # Remove the image file\n",
    "\n",
    "imageio.mimsave(f'test_visual.gif', images)  # Save the images as a GIF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model.net.hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(source_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(source_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinn_methane_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
