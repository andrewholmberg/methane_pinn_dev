{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import imageio\n",
    "from PINN import PINN\n",
    "from Net import Net\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import sklearn.mixture as mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"{os.getcwd()}/pinn_test_data\"\n",
    "# load in data\n",
    "df_wind_ch4 = pd.read_csv(data_dir + \"/wind_ch4.csv\")\n",
    "df_true_emission = pd.read_csv(data_dir + \"/selected_controll_release.csv\")\n",
    "source_points = np.load(data_dir + \"/source_points.npy\") # shape=(n_source, 3)\n",
    "sensor_points = np.load(data_dir + \"/sensor_points.npy\") # shape=(n_sensor, 3)\n",
    "#col_points = np.load(data_dir + \"/col_points.npy\")  # shape=(n_col, 3)\n",
    "df_bounds = pd.read_csv(data_dir + \"/bounds.csv\", dtype='float32')\n",
    "x_min = df_bounds['x_min'][0]\n",
    "x_max = df_bounds['x_max'][0]\n",
    "y_min = df_bounds['y_min'][0]\n",
    "y_max = df_bounds['y_max'][0]\n",
    "z_min = df_bounds['z_min'][0]\n",
    "z_max = df_bounds['z_max'][0]\n",
    "\n",
    "x_max = 1\n",
    "y_max = 1\n",
    "z_max = 1\n",
    "tfinal = 4.\n",
    "source_location = np.array([[.3,.3,.3],[.25,.75,.5]])\n",
    "\n",
    "ws = df_wind_ch4['wind_speed.m/s'].to_numpy() # shape=(N_t,)\n",
    "wd = df_wind_ch4['wind_direction'].to_numpy() # shape=(N_t,)\n",
    "ch4 = np.transpose(df_wind_ch4.iloc[:, 3:].to_numpy()) # shape=(N_obs, N_t)\n",
    "sensor_names = df_wind_ch4.columns[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\m10936927\\Documents\\methane_project\\methane_pinn_dev\\methane_pinn_dev-main\\Net.py:12: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n",
      "  torch.nn.init.xavier_uniform(m.weight)\n"
     ]
    }
   ],
   "source": [
    "sigma=.01\n",
    "model = PINN([30,30,30])\n",
    "model.set_location(source_location,[tfinal,x_max,y_max,z_max],source_values=[0,.01],sigma=sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.net.parameters(), lr=1e-4)\n",
    "# from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "# scheduler = ExponentialLR(optimizer, gamma=0.999)  # Decay LR by 5% every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 6.529e+03, grad_norm: 5.643e+02, pde_res: 6.529e+03, time: 2.802e-02\n",
      "epoch: 100, loss: 6.812e+03, grad_norm: 5.474e+02, pde_res: 6.812e+03, time: 2.387e-02\n",
      "epoch: 200, loss: 8.185e+03, grad_norm: 5.750e+02, pde_res: 8.185e+03, time: 0.000e+00\n",
      "epoch: 300, loss: 7.662e+03, grad_norm: 5.288e+02, pde_res: 7.662e+03, time: 1.012e-02\n",
      "epoch: 400, loss: 6.004e+03, grad_norm: 4.236e+02, pde_res: 6.004e+03, time: 1.668e-02\n",
      "epoch: 500, loss: 6.623e+03, grad_norm: 4.552e+02, pde_res: 6.623e+03, time: 1.000e-03\n",
      "epoch: 600, loss: 6.032e+03, grad_norm: 2.777e+02, pde_res: 6.032e+03, time: 1.585e-02\n",
      "epoch: 700, loss: 9.299e+03, grad_norm: 5.082e+02, pde_res: 9.299e+03, time: 1.747e-02\n",
      "epoch: 800, loss: 6.344e+03, grad_norm: 2.620e+02, pde_res: 6.344e+03, time: 1.562e-02\n",
      "epoch: 900, loss: 8.761e+03, grad_norm: 3.434e+02, pde_res: 8.761e+03, time: 6.672e-03\n",
      "epoch: 1000, loss: 6.138e+03, grad_norm: 1.254e+02, pde_res: 6.138e+03, time: 1.561e-02\n",
      "epoch: 1100, loss: 7.124e+03, grad_norm: 1.899e+02, pde_res: 7.124e+03, time: 1.201e-02\n",
      "epoch: 1200, loss: 6.981e+03, grad_norm: 1.843e+02, pde_res: 6.981e+03, time: 0.000e+00\n",
      "epoch: 1300, loss: 6.116e+03, grad_norm: 9.314e+01, pde_res: 6.116e+03, time: 2.000e-03\n",
      "epoch: 1400, loss: 5.993e+03, grad_norm: 1.904e+02, pde_res: 5.993e+03, time: 1.693e-02\n",
      "epoch: 1500, loss: 7.743e+03, grad_norm: 3.234e+02, pde_res: 7.743e+03, time: 0.000e+00\n",
      "epoch: 1600, loss: 7.322e+03, grad_norm: 2.225e+02, pde_res: 7.322e+03, time: 1.564e-02\n",
      "epoch: 1700, loss: 6.375e+03, grad_norm: 1.682e+02, pde_res: 6.375e+03, time: 1.565e-02\n",
      "epoch: 1800, loss: 5.080e+03, grad_norm: 2.903e+02, pde_res: 5.080e+03, time: 0.000e+00\n",
      "epoch: 1900, loss: 6.816e+03, grad_norm: 2.053e+02, pde_res: 6.816e+03, time: 1.451e-02\n",
      "epoch: 2000, loss: 7.576e+03, grad_norm: 1.647e+02, pde_res: 7.576e+03, time: 1.562e-02\n",
      "epoch: 2100, loss: 5.666e+03, grad_norm: 1.805e+02, pde_res: 5.666e+03, time: 1.566e-02\n",
      "epoch: 2200, loss: 5.534e+03, grad_norm: 3.155e+02, pde_res: 5.534e+03, time: 0.000e+00\n",
      "epoch: 2300, loss: 8.161e+03, grad_norm: 2.242e+02, pde_res: 8.161e+03, time: 1.326e-02\n",
      "epoch: 2400, loss: 6.310e+03, grad_norm: 1.538e+02, pde_res: 6.310e+03, time: 0.000e+00\n",
      "epoch: 2500, loss: 8.887e+03, grad_norm: 5.534e+02, pde_res: 8.887e+03, time: 1.582e-02\n",
      "epoch: 2600, loss: 5.974e+03, grad_norm: 2.242e+02, pde_res: 5.974e+03, time: 0.000e+00\n",
      "epoch: 2700, loss: 7.281e+03, grad_norm: 3.493e+02, pde_res: 7.280e+03, time: 0.000e+00\n",
      "epoch: 2800, loss: 5.875e+03, grad_norm: 2.364e+02, pde_res: 5.875e+03, time: 0.000e+00\n",
      "epoch: 2900, loss: 5.817e+03, grad_norm: 3.177e+02, pde_res: 5.813e+03, time: 1.719e-02\n",
      "epoch: 3000, loss: 6.433e+03, grad_norm: 3.527e+02, pde_res: 6.432e+03, time: 0.000e+00\n",
      "epoch: 3100, loss: 5.212e+03, grad_norm: 5.504e+02, pde_res: 5.212e+03, time: 9.109e-03\n",
      "epoch: 3200, loss: 4.610e+03, grad_norm: 3.256e+02, pde_res: 4.608e+03, time: 1.124e-03\n",
      "epoch: 3300, loss: 5.383e+03, grad_norm: 2.705e+02, pde_res: 5.383e+03, time: 0.000e+00\n",
      "epoch: 3400, loss: 6.591e+03, grad_norm: 6.563e+02, pde_res: 6.590e+03, time: 1.815e-02\n",
      "epoch: 3500, loss: 5.957e+03, grad_norm: 3.614e+02, pde_res: 5.957e+03, time: 0.000e+00\n",
      "epoch: 3600, loss: 6.494e+03, grad_norm: 3.593e+02, pde_res: 6.492e+03, time: 1.681e-02\n",
      "epoch: 3700, loss: 6.702e+03, grad_norm: 3.674e+02, pde_res: 6.699e+03, time: 8.327e-03\n",
      "epoch: 3800, loss: 6.232e+03, grad_norm: 8.524e+02, pde_res: 6.230e+03, time: 2.252e-02\n",
      "epoch: 3900, loss: 6.686e+03, grad_norm: 7.887e+02, pde_res: 6.685e+03, time: 1.373e-02\n",
      "epoch: 4000, loss: 5.164e+03, grad_norm: 3.862e+02, pde_res: 5.162e+03, time: 1.989e-02\n",
      "epoch: 4100, loss: 6.768e+03, grad_norm: 5.932e+02, pde_res: 6.766e+03, time: 1.673e-02\n",
      "epoch: 4200, loss: 6.995e+03, grad_norm: 7.126e+02, pde_res: 6.992e+03, time: 1.653e-02\n",
      "epoch: 4300, loss: 6.336e+03, grad_norm: 3.171e+02, pde_res: 6.335e+03, time: 1.338e-02\n",
      "epoch: 4400, loss: 7.060e+03, grad_norm: 4.119e+02, pde_res: 7.059e+03, time: 0.000e+00\n",
      "epoch: 4500, loss: 5.464e+03, grad_norm: 5.743e+02, pde_res: 5.463e+03, time: 1.666e-02\n",
      "epoch: 4600, loss: 5.479e+03, grad_norm: 5.895e+02, pde_res: 5.476e+03, time: 2.136e-03\n",
      "epoch: 4700, loss: 5.686e+03, grad_norm: 4.103e+02, pde_res: 5.685e+03, time: 0.000e+00\n",
      "epoch: 4800, loss: 7.049e+03, grad_norm: 5.259e+02, pde_res: 7.047e+03, time: 8.908e-03\n",
      "epoch: 4900, loss: 5.911e+03, grad_norm: 8.688e+02, pde_res: 5.911e+03, time: 0.000e+00\n",
      "epoch: 5000, loss: 6.258e+03, grad_norm: 7.267e+02, pde_res: 6.258e+03, time: 0.000e+00\n",
      "epoch: 5100, loss: 6.385e+03, grad_norm: 1.070e+03, pde_res: 6.384e+03, time: 0.000e+00\n",
      "epoch: 5200, loss: 6.683e+03, grad_norm: 3.450e+02, pde_res: 6.683e+03, time: 1.363e-02\n",
      "epoch: 5300, loss: 6.759e+03, grad_norm: 7.706e+02, pde_res: 6.758e+03, time: 1.391e-02\n",
      "epoch: 5400, loss: 6.743e+03, grad_norm: 4.782e+02, pde_res: 6.741e+03, time: 0.000e+00\n",
      "epoch: 5500, loss: 6.772e+03, grad_norm: 7.911e+02, pde_res: 6.770e+03, time: 7.146e-03\n",
      "epoch: 5600, loss: 7.108e+03, grad_norm: 7.958e+02, pde_res: 7.107e+03, time: 1.664e-02\n",
      "epoch: 5700, loss: 5.577e+03, grad_norm: 7.666e+02, pde_res: 5.576e+03, time: 5.519e-04\n",
      "epoch: 5800, loss: 6.692e+03, grad_norm: 7.922e+02, pde_res: 6.691e+03, time: 7.937e-03\n",
      "epoch: 5900, loss: 5.589e+03, grad_norm: 5.829e+02, pde_res: 5.585e+03, time: 1.330e-02\n",
      "epoch: 6000, loss: 6.903e+03, grad_norm: 2.131e+03, pde_res: 6.902e+03, time: 1.673e-02\n",
      "epoch: 6100, loss: 6.456e+03, grad_norm: 8.012e+02, pde_res: 6.455e+03, time: 6.504e-04\n",
      "epoch: 6200, loss: 5.065e+03, grad_norm: 5.469e+02, pde_res: 5.063e+03, time: 0.000e+00\n",
      "epoch: 6300, loss: 5.923e+03, grad_norm: 2.479e+03, pde_res: 5.918e+03, time: 0.000e+00\n",
      "epoch: 6400, loss: 6.490e+03, grad_norm: 5.185e+02, pde_res: 6.489e+03, time: 1.003e-02\n",
      "epoch: 6500, loss: 6.612e+03, grad_norm: 9.149e+02, pde_res: 6.611e+03, time: 1.355e-02\n",
      "epoch: 6600, loss: 6.210e+03, grad_norm: 8.522e+02, pde_res: 6.210e+03, time: 1.213e-03\n",
      "epoch: 6700, loss: 6.622e+03, grad_norm: 1.471e+03, pde_res: 6.621e+03, time: 1.659e-02\n",
      "epoch: 6800, loss: 5.676e+03, grad_norm: 1.073e+03, pde_res: 5.674e+03, time: 8.010e-03\n",
      "epoch: 6900, loss: 6.224e+03, grad_norm: 5.041e+02, pde_res: 6.224e+03, time: 8.994e-03\n",
      "epoch: 7000, loss: 5.638e+03, grad_norm: 1.206e+03, pde_res: 5.638e+03, time: 1.561e-02\n",
      "epoch: 7100, loss: 6.284e+03, grad_norm: 2.956e+03, pde_res: 6.282e+03, time: 1.004e-02\n",
      "epoch: 7200, loss: 6.269e+03, grad_norm: 8.214e+02, pde_res: 6.266e+03, time: 2.054e-02\n",
      "epoch: 7300, loss: 5.587e+03, grad_norm: 2.524e+03, pde_res: 5.585e+03, time: 1.734e-02\n",
      "epoch: 7400, loss: 6.642e+03, grad_norm: 6.782e+02, pde_res: 6.642e+03, time: 1.943e-02\n",
      "epoch: 7500, loss: 6.181e+03, grad_norm: 1.824e+03, pde_res: 6.181e+03, time: 1.898e-02\n",
      "epoch: 7600, loss: 6.259e+03, grad_norm: 4.525e+03, pde_res: 6.259e+03, time: 5.221e-04\n",
      "epoch: 7700, loss: 6.765e+03, grad_norm: 9.566e+02, pde_res: 6.765e+03, time: 0.000e+00\n",
      "epoch: 7800, loss: 6.975e+03, grad_norm: 1.146e+03, pde_res: 6.974e+03, time: 0.000e+00\n",
      "epoch: 7900, loss: 7.577e+03, grad_norm: 2.467e+03, pde_res: 7.573e+03, time: 1.668e-02\n",
      "epoch: 8000, loss: 6.499e+03, grad_norm: 7.373e+02, pde_res: 6.498e+03, time: 0.000e+00\n",
      "epoch: 8100, loss: 6.069e+03, grad_norm: 8.958e+02, pde_res: 6.060e+03, time: 1.990e-02\n",
      "epoch: 8200, loss: 5.162e+03, grad_norm: 9.901e+02, pde_res: 5.162e+03, time: 1.670e-02\n",
      "epoch: 8300, loss: 5.250e+03, grad_norm: 2.598e+03, pde_res: 5.249e+03, time: 7.873e-03\n",
      "epoch: 8400, loss: 5.831e+03, grad_norm: 2.120e+03, pde_res: 5.826e+03, time: 1.364e-02\n",
      "epoch: 8500, loss: 7.862e+03, grad_norm: 1.865e+03, pde_res: 7.861e+03, time: 0.000e+00\n",
      "epoch: 8600, loss: 7.009e+03, grad_norm: 3.771e+03, pde_res: 7.005e+03, time: 0.000e+00\n",
      "epoch: 8700, loss: 5.367e+03, grad_norm: 2.687e+03, pde_res: 5.363e+03, time: 4.268e-03\n",
      "epoch: 8800, loss: 5.569e+03, grad_norm: 1.830e+03, pde_res: 5.559e+03, time: 0.000e+00\n",
      "epoch: 8900, loss: 6.209e+03, grad_norm: 1.106e+03, pde_res: 6.207e+03, time: 1.810e-02\n",
      "epoch: 9000, loss: 5.170e+03, grad_norm: 2.667e+03, pde_res: 5.159e+03, time: 1.471e-02\n",
      "epoch: 9100, loss: 6.616e+03, grad_norm: 2.711e+03, pde_res: 6.605e+03, time: 1.660e-02\n",
      "epoch: 9200, loss: 5.460e+03, grad_norm: 1.411e+03, pde_res: 5.459e+03, time: 1.678e-02\n",
      "epoch: 9300, loss: 6.183e+03, grad_norm: 2.362e+03, pde_res: 6.183e+03, time: 1.034e-02\n",
      "epoch: 9400, loss: 5.814e+03, grad_norm: 2.834e+03, pde_res: 5.814e+03, time: 1.001e-02\n",
      "epoch: 9500, loss: 3.783e+03, grad_norm: 3.494e+03, pde_res: 3.783e+03, time: 6.746e-03\n",
      "epoch: 9600, loss: 5.192e+03, grad_norm: 2.823e+03, pde_res: 5.188e+03, time: 1.667e-02\n",
      "epoch: 9700, loss: 6.122e+03, grad_norm: 2.786e+03, pde_res: 6.119e+03, time: 1.724e-02\n",
      "epoch: 9800, loss: 6.615e+03, grad_norm: 3.181e+03, pde_res: 6.614e+03, time: 0.000e+00\n",
      "epoch: 9900, loss: 7.090e+03, grad_norm: 2.211e+03, pde_res: 7.089e+03, time: 2.321e-02\n",
      "epoch: 10000, loss: 3.558e+03, grad_norm: 3.507e+03, pde_res: 3.554e+03, time: 1.933e-02\n",
      "epoch: 10100, loss: 6.669e+03, grad_norm: 8.546e+02, pde_res: 6.666e+03, time: 1.669e-02\n",
      "epoch: 10200, loss: 5.187e+03, grad_norm: 1.167e+03, pde_res: 5.185e+03, time: 4.717e-03\n",
      "epoch: 10300, loss: 5.743e+03, grad_norm: 1.613e+03, pde_res: 5.735e+03, time: 2.245e-02\n",
      "epoch: 10400, loss: 7.272e+03, grad_norm: 3.422e+03, pde_res: 7.269e+03, time: 0.000e+00\n",
      "epoch: 10500, loss: 5.643e+03, grad_norm: 1.181e+03, pde_res: 5.641e+03, time: 1.128e-02\n",
      "epoch: 10600, loss: 6.047e+03, grad_norm: 2.722e+03, pde_res: 6.045e+03, time: 2.031e-02\n",
      "epoch: 10700, loss: 5.330e+03, grad_norm: 2.166e+03, pde_res: 5.327e+03, time: 1.999e-02\n",
      "epoch: 10800, loss: 6.405e+03, grad_norm: 1.330e+03, pde_res: 6.405e+03, time: 1.116e-02\n",
      "epoch: 10900, loss: 6.549e+03, grad_norm: 2.850e+03, pde_res: 6.538e+03, time: 2.356e-03\n",
      "epoch: 11000, loss: 6.264e+03, grad_norm: 1.951e+03, pde_res: 6.260e+03, time: 1.012e-02\n",
      "epoch: 11100, loss: 5.362e+03, grad_norm: 1.186e+03, pde_res: 5.362e+03, time: 1.551e-02\n",
      "epoch: 11200, loss: 4.604e+03, grad_norm: 2.341e+03, pde_res: 4.603e+03, time: 0.000e+00\n",
      "epoch: 11300, loss: 5.146e+03, grad_norm: 2.219e+03, pde_res: 5.143e+03, time: 1.959e-02\n",
      "epoch: 11400, loss: 5.184e+03, grad_norm: 2.448e+03, pde_res: 5.168e+03, time: 0.000e+00\n",
      "epoch: 11500, loss: 5.341e+03, grad_norm: 2.308e+03, pde_res: 5.332e+03, time: 1.661e-02\n",
      "epoch: 11600, loss: 6.131e+03, grad_norm: 3.173e+03, pde_res: 6.130e+03, time: 0.000e+00\n",
      "epoch: 11700, loss: 6.153e+03, grad_norm: 3.705e+03, pde_res: 6.153e+03, time: 2.330e-02\n",
      "epoch: 11800, loss: 5.366e+03, grad_norm: 2.539e+03, pde_res: 5.362e+03, time: 2.032e-02\n",
      "epoch: 11900, loss: 4.848e+03, grad_norm: 6.504e+03, pde_res: 4.848e+03, time: 1.215e-02\n",
      "epoch: 12000, loss: 5.460e+03, grad_norm: 3.871e+03, pde_res: 5.459e+03, time: 1.316e-02\n",
      "epoch: 12100, loss: 5.507e+03, grad_norm: 3.722e+03, pde_res: 5.501e+03, time: 4.377e-03\n",
      "epoch: 12200, loss: 5.924e+03, grad_norm: 1.784e+03, pde_res: 5.918e+03, time: 5.226e-04\n",
      "epoch: 12300, loss: 6.619e+03, grad_norm: 5.167e+03, pde_res: 6.618e+03, time: 1.833e-02\n",
      "epoch: 12400, loss: 4.735e+03, grad_norm: 5.888e+03, pde_res: 4.729e+03, time: 0.000e+00\n",
      "epoch: 12500, loss: 5.796e+03, grad_norm: 4.759e+03, pde_res: 5.795e+03, time: 1.657e-02\n",
      "epoch: 12600, loss: 5.386e+03, grad_norm: 2.639e+03, pde_res: 5.383e+03, time: 2.143e-02\n",
      "epoch: 12700, loss: 5.700e+03, grad_norm: 7.972e+03, pde_res: 5.700e+03, time: 1.563e-02\n",
      "epoch: 12800, loss: 5.392e+03, grad_norm: 2.547e+03, pde_res: 5.392e+03, time: 1.659e-02\n",
      "epoch: 12900, loss: 4.936e+03, grad_norm: 6.928e+03, pde_res: 4.936e+03, time: 2.047e-02\n",
      "epoch: 13000, loss: 5.500e+03, grad_norm: 6.096e+03, pde_res: 5.500e+03, time: 0.000e+00\n",
      "epoch: 13100, loss: 5.422e+03, grad_norm: 2.239e+03, pde_res: 5.422e+03, time: 1.425e-02\n",
      "epoch: 13200, loss: 5.364e+03, grad_norm: 2.732e+03, pde_res: 5.348e+03, time: 0.000e+00\n",
      "epoch: 13300, loss: 4.729e+03, grad_norm: 2.977e+03, pde_res: 4.719e+03, time: 0.000e+00\n",
      "epoch: 13400, loss: 5.883e+03, grad_norm: 7.222e+03, pde_res: 5.883e+03, time: 0.000e+00\n",
      "epoch: 13500, loss: 5.863e+03, grad_norm: 7.526e+03, pde_res: 5.859e+03, time: 1.127e-02\n",
      "epoch: 13600, loss: 5.131e+03, grad_norm: 1.143e+04, pde_res: 5.131e+03, time: 2.072e-02\n",
      "epoch: 13700, loss: 6.121e+03, grad_norm: 7.191e+03, pde_res: 6.111e+03, time: 6.261e-04\n",
      "epoch: 13800, loss: 5.368e+03, grad_norm: 5.699e+03, pde_res: 5.368e+03, time: 2.236e-02\n",
      "epoch: 13900, loss: 4.832e+03, grad_norm: 3.134e+03, pde_res: 4.830e+03, time: 1.649e-02\n",
      "epoch: 14000, loss: 3.761e+03, grad_norm: 4.957e+03, pde_res: 3.755e+03, time: 1.651e-02\n",
      "epoch: 14100, loss: 5.229e+03, grad_norm: 1.293e+04, pde_res: 5.227e+03, time: 5.724e-03\n",
      "epoch: 14200, loss: 4.994e+03, grad_norm: 5.087e+03, pde_res: 4.994e+03, time: 1.100e-02\n",
      "epoch: 14300, loss: 6.723e+03, grad_norm: 8.650e+03, pde_res: 6.722e+03, time: 1.035e-02\n",
      "epoch: 14400, loss: 5.626e+03, grad_norm: 2.363e+04, pde_res: 5.623e+03, time: 2.146e-02\n",
      "epoch: 14500, loss: 6.315e+03, grad_norm: 7.907e+03, pde_res: 6.315e+03, time: 2.247e-02\n",
      "epoch: 14600, loss: 4.179e+03, grad_norm: 1.113e+04, pde_res: 4.134e+03, time: 1.662e-02\n",
      "epoch: 14700, loss: 4.982e+03, grad_norm: 4.738e+03, pde_res: 4.979e+03, time: 0.000e+00\n",
      "epoch: 14800, loss: 5.554e+03, grad_norm: 2.059e+04, pde_res: 5.549e+03, time: 1.431e-02\n",
      "epoch: 14900, loss: 5.268e+03, grad_norm: 4.519e+03, pde_res: 5.268e+03, time: 2.028e-02\n",
      "epoch: 15000, loss: 5.533e+03, grad_norm: 7.756e+03, pde_res: 5.532e+03, time: 2.049e-02\n",
      "epoch: 15100, loss: 3.966e+03, grad_norm: 8.006e+03, pde_res: 3.959e+03, time: 1.650e-02\n",
      "epoch: 15200, loss: 4.727e+03, grad_norm: 4.302e+03, pde_res: 4.723e+03, time: 0.000e+00\n",
      "epoch: 15300, loss: 5.017e+03, grad_norm: 1.472e+04, pde_res: 5.016e+03, time: 1.100e-02\n",
      "epoch: 15400, loss: 4.827e+03, grad_norm: 9.932e+03, pde_res: 4.824e+03, time: 1.646e-02\n",
      "epoch: 15500, loss: 4.790e+03, grad_norm: 3.918e+04, pde_res: 4.790e+03, time: 1.663e-02\n",
      "epoch: 15600, loss: 4.262e+03, grad_norm: 6.182e+03, pde_res: 4.262e+03, time: 1.652e-02\n",
      "epoch: 15700, loss: 4.435e+03, grad_norm: 4.774e+03, pde_res: 4.434e+03, time: 1.666e-02\n",
      "epoch: 15800, loss: 5.505e+03, grad_norm: 1.277e+04, pde_res: 5.504e+03, time: 1.675e-02\n",
      "epoch: 15900, loss: 6.589e+03, grad_norm: 7.616e+03, pde_res: 6.589e+03, time: 1.506e-02\n",
      "epoch: 16000, loss: 4.717e+03, grad_norm: 7.807e+03, pde_res: 4.716e+03, time: 2.118e-03\n",
      "epoch: 16100, loss: 5.961e+03, grad_norm: 8.420e+03, pde_res: 5.960e+03, time: 9.868e-03\n",
      "epoch: 16200, loss: 5.226e+03, grad_norm: 1.981e+04, pde_res: 5.226e+03, time: 1.657e-02\n",
      "epoch: 16300, loss: 4.795e+03, grad_norm: 9.599e+03, pde_res: 4.794e+03, time: 1.668e-02\n",
      "epoch: 16400, loss: 3.789e+03, grad_norm: 5.127e+04, pde_res: 3.789e+03, time: 1.201e-02\n",
      "epoch: 16500, loss: 5.989e+03, grad_norm: 1.796e+04, pde_res: 5.988e+03, time: 2.043e-02\n",
      "epoch: 16600, loss: 4.451e+03, grad_norm: 2.118e+04, pde_res: 4.444e+03, time: 8.914e-03\n",
      "epoch: 16700, loss: 6.153e+03, grad_norm: 2.015e+04, pde_res: 6.151e+03, time: 0.000e+00\n",
      "epoch: 16800, loss: 5.433e+03, grad_norm: 1.168e+04, pde_res: 5.433e+03, time: 1.344e-03\n",
      "epoch: 16900, loss: 5.743e+03, grad_norm: 1.435e+04, pde_res: 5.739e+03, time: 1.666e-02\n",
      "epoch: 17000, loss: 4.224e+03, grad_norm: 1.157e+04, pde_res: 4.224e+03, time: 2.890e-03\n",
      "epoch: 17100, loss: 5.947e+03, grad_norm: 1.814e+04, pde_res: 5.946e+03, time: 1.353e-02\n",
      "epoch: 17200, loss: 5.458e+03, grad_norm: 2.539e+04, pde_res: 5.457e+03, time: 0.000e+00\n",
      "epoch: 17300, loss: 5.109e+03, grad_norm: 3.612e+04, pde_res: 5.109e+03, time: 2.060e-02\n",
      "epoch: 17400, loss: 4.675e+03, grad_norm: 4.737e+03, pde_res: 4.675e+03, time: 1.501e-02\n",
      "epoch: 17500, loss: 5.369e+03, grad_norm: 4.747e+04, pde_res: 5.369e+03, time: 1.562e-02\n",
      "epoch: 17600, loss: 4.735e+03, grad_norm: 5.979e+04, pde_res: 4.735e+03, time: 1.862e-02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 41\u001b[0m\n\u001b[0;32m     35\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_1\u001b[38;5;241m+\u001b[39mloss_2\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# # print loss at first epoch\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# if epoch == 0:\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m#     print('epoch: %d, loss: %1.3e, pde_res: %1.3e, source_loss: %1.3e' % (epoch, loss.item(), loss_1.item(), loss_2.item()))\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# compute norm of gradient of the network\u001b[39;00m\n\u001b[0;32m     44\u001b[0m grad_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    625\u001b[0m     )\n\u001b[1;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n= int(5e2)\n",
    "# n=1\n",
    "sn = int(5e2)\n",
    "best_loss = np.inf\n",
    "max_epochs = int(2e4)\n",
    "print_freq = 100\n",
    "\n",
    "sampling_freq = 10 # how often to resample collocation and source points\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    start_time = time.time()\n",
    "    if epoch % sampling_freq == 0:\n",
    "        # points for source PDE loss. uvpoints are wind field at different times. source_values is the value of source at source_colloc_points (assumes Gaussian for now)\n",
    "        source_collocation_points = model.source_points(sn,2*sigma) \n",
    "        # source_uv_points = torch.ones(len(source_collocation_points),2)*.5\n",
    "        # initial condition collocation points with smaller time values 0.1*t_final. \n",
    "        # ic_col = torch.cat([torch.rand(sn,1)*tfinal*.1, torch.rand(sn,1)*x_max, torch.rand(sn,1)*y_max, torch.rand(sn,1)*z_max], dim=1)\n",
    "        collocation_points = torch.cat([torch.rand(n,1)*tfinal, torch.rand(n,1)*x_max*2 - x_max/2, torch.rand(n,1)*y_max*2 - y_max/2, torch.rand(n,1)*z_max*2-z_max/2], dim=1)\n",
    "        # collocation_points = torch.cat([collocation_points,ic_col,source_collocation_points])\n",
    "        collocation_points = torch.cat([collocation_points,source_collocation_points])\n",
    "        collocation_points.requires_grad_(True)\n",
    "        # collocation_points.requires_grad=True\n",
    "        uv = torch.ones(len(collocation_points),2)*.1#wind tensor\n",
    "        # print(collocation_points[-2])\n",
    "        uv[:,1:]*= -1\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss_1 ,pde_1 = model.compute_pde_loss(collocation_points,uv) # PDE residual loss\n",
    "    loss_2 = model.compute_negative_loss(collocation_points)\n",
    "    # loss_2,pde_2 = model.loss_function(source_collocation_points, source_uv_points) # source term PDE residual loss \n",
    "    # loss_3 ,pde_3 = model.loss_function(torch.concat([collocation_points,source_collocation_points]),torch.concat([collocation_points,source_collocation_points]))\n",
    "\n",
    "    # loss = loss_1 + loss_2\n",
    "    # loss = loss_2*100\n",
    "    loss = loss_1+loss_2*100\n",
    "\n",
    "    # # print loss at first epoch\n",
    "    # if epoch == 0:\n",
    "    #     print('epoch: %d, loss: %1.3e, pde_res: %1.3e, source_loss: %1.3e' % (epoch, loss.item(), loss_1.item(), loss_2.item()))\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # compute norm of gradient of the network\n",
    "    grad_norm = 0\n",
    "    for p in model.net.parameters():\n",
    "        grad_norm += p.grad.data.norm(2).item()**2\n",
    "    grad_norm = grad_norm**0.5\n",
    "\n",
    "\n",
    "    if loss.item() < best_loss:\n",
    "        torch.save(model,'best_mod.m')\n",
    "    optimizer.step()\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    # scheduler.step()\n",
    "\n",
    "    if epoch % print_freq == 0:\n",
    "\n",
    "        # print epoch and loss using %1.3e format\n",
    "        # print('epoch: %d, loss: %1.3e, grad_norm: %1.3e, pde_res: %1.3e, source_loss: %1.3e, time: %1.3e' % (epoch, loss.item(), grad_norm, loss_1.item(), loss_2.item(), epoch_time))\n",
    "        print('epoch: %d, loss: %1.3e, grad_norm: %1.3e, pde_res: %1.3e, time: %1.3e' % (epoch, loss.item(), grad_norm, loss_1.item(), epoch_time))\n",
    "\n",
    "        # print(epoch, loss.item())\n",
    "        # print(loss_2.item(),loss_1.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(x_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL PINN.PINN was not an allowed global by default. Please use `torch.serialization.add_safe_globals([PINN])` or the `torch.serialization.safe_globals([PINN])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_mod.m\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\serialization.py:1470\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1462\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[0;32m   1463\u001b[0m                     opened_zipfile,\n\u001b[0;32m   1464\u001b[0m                     map_location,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1467\u001b[0m                     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[0;32m   1468\u001b[0m                 )\n\u001b[0;32m   1469\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1470\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1471\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[0;32m   1472\u001b[0m             opened_zipfile,\n\u001b[0;32m   1473\u001b[0m             map_location,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1476\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[0;32m   1477\u001b[0m         )\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL PINN.PINN was not an allowed global by default. Please use `torch.serialization.add_safe_globals([PINN])` or the `torch.serialization.safe_globals([PINN])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "source": [
    "model = torch.load('best_mod.m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Plot the concentration over time\\nfor t in time_steps:\\n    t_tensor = torch.full((grid_points.shape[0], 1), t, dtype=torch.float32)  # Time input\\n    concentration = net(grid_points, t_tensor).cpu().detach().numpy().reshape(100, 100)  # Predict and reshape\\n    \\n    plt.figure()\\n    plt.contourf(X, Y, concentration, levels=50, cmap=\\'viridis\\', vmin=0, vmax=10)  # Plot concentration as a contour plot\\n    plt.plot(source_loc[0,0].cpu(), source_loc[0,1].cpu(), \\'ro\\', label=\\'Source Location\\')  # Plot the source location\\n    plt.colorbar(label=\\'Concentration\\')\\n    # fix colorbar from 0 to 1 \\n    # plt.clim(0, 10.0)  # Set colorbar limits\\n    plt.title(f\"Gas Concentration at t = {t:.2f}\")\\n    plt.xlabel(\\'x\\')\\n    plt.ylabel(\\'y\\')\\n    # fix colorbar \\n    # plt.savefig(f\"concentration_t_{t:.2f}.png\")  # Save the plot as an image\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load the best model \n",
    "Z_value = .5\n",
    "# net.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Define the grid and time steps\n",
    "n= 100\n",
    "x_grid = np.linspace(0, x_max, n)\n",
    "y_grid = np.linspace(0, y_max, n)\n",
    "z_grid = np.linspace(0, z_max, n)\n",
    "\n",
    "X, Y, = np.meshgrid(x_grid, y_grid)\n",
    "Z= X * 0 + Z_value\n",
    "\n",
    "grid_points = np.vstack([X.ravel(), Y.ravel(), Z.ravel()]).T\n",
    "# grid_points = np.vstack([X.ravel(), Y.ravel(), Z.ravel()]).T  # Flatten the grid\n",
    "grid_points = torch.tensor(grid_points, dtype=torch.float32)\n",
    "\n",
    "time_steps = np.linspace(0, tfinal, 20)  # 10 time steps from 0 to 1\n",
    "\n",
    "\n",
    "'''\n",
    "# Plot the concentration over time\n",
    "for t in time_steps:\n",
    "    t_tensor = torch.full((grid_points.shape[0], 1), t, dtype=torch.float32)  # Time input\n",
    "    concentration = net(grid_points, t_tensor).cpu().detach().numpy().reshape(100, 100)  # Predict and reshape\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.contourf(X, Y, concentration, levels=50, cmap='viridis', vmin=0, vmax=10)  # Plot concentration as a contour plot\n",
    "    plt.plot(source_loc[0,0].cpu(), source_loc[0,1].cpu(), 'ro', label='Source Location')  # Plot the source location\n",
    "    plt.colorbar(label='Concentration')\n",
    "    # fix colorbar from 0 to 1 \n",
    "    # plt.clim(0, 10.0)  # Set colorbar limits\n",
    "    plt.title(f\"Gas Concentration at t = {t:.2f}\")\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    # fix colorbar \n",
    "    # plt.savefig(f\"concentration_t_{t:.2f}.png\")  # Save the plot as an image\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m10936927\\AppData\\Local\\Temp\\ipykernel_16652\\3356015117.py:22: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images.append(imageio.imread(f\"concentration_t_{t:.2f}.png\"))  # Append the image to the list\n"
     ]
    }
   ],
   "source": [
    "# save as a GIF\n",
    "import imageio\n",
    "import os\n",
    "\n",
    "images = []\n",
    "# source_loc = torch.tensor([[.5,.5,.5]])\n",
    "source_loc = model.source_locs\n",
    "for t in time_steps:\n",
    "    t_tensor = torch.full((grid_points.shape[0], 1), t, dtype=torch.float32)  # Time input\n",
    "    concentration = model.forward(torch.cat([t_tensor,grid_points],dim=1),scaled=True).cpu().detach().numpy().reshape(100, 100)  # Predict and reshape\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.contourf(X, Y, concentration, levels=50, cmap='viridis', vmin=0, vmax=100)  # Plot concentration as a contour plot\n",
    "    plt.plot(model.source_locs[1,0], model.source_locs[1,1], 'ro', label='Source Location')  # Plot the source location\n",
    "    plt.colorbar(label='Concentration')\n",
    "    plt.title(f\"Gas Concentration at t = {t:.2f}\")\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.savefig(f\"concentration_t_{t:.2f}.png\")  # Save the plot as an image\n",
    "    plt.close()\n",
    "    \n",
    "    images.append(imageio.imread(f\"concentration_t_{t:.2f}.png\"))  # Append the image to the list\n",
    "    os.remove(f\"concentration_t_{t:.2f}.png\")  # Remove the image file\n",
    "\n",
    "imageio.mimsave(f'test_visual_basic.gif', images)  # Save the images as a GIF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model.net.hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(source_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
