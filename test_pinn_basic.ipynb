{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import imageio\n",
    "from PINN import PINN\n",
    "from Net import Net\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import sklearn.mixture as mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"{os.getcwd()}/pinn_test_data\"\n",
    "# load in data\n",
    "df_wind_ch4 = pd.read_csv(data_dir + \"/wind_ch4.csv\")\n",
    "df_true_emission = pd.read_csv(data_dir + \"/selected_controll_release.csv\")\n",
    "source_points = np.load(data_dir + \"/source_points.npy\") # shape=(n_source, 3)\n",
    "sensor_points = np.load(data_dir + \"/sensor_points.npy\") # shape=(n_sensor, 3)\n",
    "#col_points = np.load(data_dir + \"/col_points.npy\")  # shape=(n_col, 3)\n",
    "df_bounds = pd.read_csv(data_dir + \"/bounds.csv\", dtype='float32')\n",
    "x_min = df_bounds['x_min'][0]\n",
    "x_max = df_bounds['x_max'][0]\n",
    "y_min = df_bounds['y_min'][0]\n",
    "y_max = df_bounds['y_max'][0]\n",
    "z_min = df_bounds['z_min'][0]\n",
    "z_max = df_bounds['z_max'][0]\n",
    "\n",
    "x_max = 1\n",
    "y_max = 1\n",
    "z_max = 1\n",
    "tfinal = 4.\n",
    "source_location = np.array([[.1,.9,.5],[.9,.9,.5]])\n",
    "\n",
    "ws = df_wind_ch4['wind_speed.m/s'].to_numpy() # shape=(N_t,)\n",
    "wd = df_wind_ch4['wind_direction'].to_numpy() # shape=(N_t,)\n",
    "ch4 = np.transpose(df_wind_ch4.iloc[:, 3:].to_numpy()) # shape=(N_obs, N_t)\n",
    "sensor_names = df_wind_ch4.columns[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\andyh\\Documents\\Projects\\mines\\methane_project\\methane_pinn_dev\\Net.py:12: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(m.weight)\n"
     ]
    }
   ],
   "source": [
    "sigma=.05\n",
    "model = PINN([30,30,30,30,30])\n",
    "model.set_location(source_location,[tfinal,x_max,y_max,z_max],source_values=[.005,.005],sigma=sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.net.parameters(), lr=1e-4)\n",
    "# from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "# scheduler = ExponentialLR(optimizer, gamma=0.999)  # Decay LR by 5% every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1.792e-01, grad_norm: 8.667e-01, pde_res: 1.703e-01, time: 1.332e-02\n",
      "epoch: 100, loss: 1.390e-01, grad_norm: 2.256e-01, pde_res: 1.385e-01, time: 1.238e-02\n",
      "epoch: 200, loss: 1.427e-01, grad_norm: 3.402e-01, pde_res: 1.423e-01, time: 1.114e-02\n",
      "epoch: 300, loss: 1.465e-01, grad_norm: 3.874e-01, pde_res: 1.459e-01, time: 1.219e-02\n",
      "epoch: 400, loss: 1.377e-01, grad_norm: 1.290e-01, pde_res: 1.376e-01, time: 1.055e-02\n",
      "epoch: 500, loss: 1.330e-01, grad_norm: 2.093e-01, pde_res: 1.327e-01, time: 1.226e-02\n",
      "epoch: 600, loss: 1.301e-01, grad_norm: 1.154e-01, pde_res: 1.301e-01, time: 1.039e-02\n",
      "epoch: 700, loss: 1.238e-01, grad_norm: 3.310e-01, pde_res: 1.237e-01, time: 1.087e-02\n",
      "epoch: 800, loss: 1.423e-01, grad_norm: 3.407e-01, pde_res: 1.423e-01, time: 1.058e-02\n",
      "epoch: 900, loss: 1.296e-01, grad_norm: 8.399e-02, pde_res: 1.296e-01, time: 1.126e-02\n",
      "epoch: 1000, loss: 1.300e-01, grad_norm: 1.514e-01, pde_res: 1.299e-01, time: 1.101e-02\n",
      "epoch: 1100, loss: 1.306e-01, grad_norm: 1.128e-01, pde_res: 1.306e-01, time: 1.147e-02\n",
      "epoch: 1200, loss: 1.312e-01, grad_norm: 1.268e-01, pde_res: 1.311e-01, time: 1.256e-02\n",
      "epoch: 1300, loss: 1.245e-01, grad_norm: 8.270e-02, pde_res: 1.244e-01, time: 1.202e-02\n",
      "epoch: 1400, loss: 1.284e-01, grad_norm: 1.236e-01, pde_res: 1.284e-01, time: 1.214e-02\n",
      "epoch: 1500, loss: 1.240e-01, grad_norm: 5.841e-02, pde_res: 1.239e-01, time: 1.255e-02\n",
      "epoch: 1600, loss: 1.349e-01, grad_norm: 4.453e-02, pde_res: 1.348e-01, time: 1.178e-02\n",
      "epoch: 1700, loss: 1.248e-01, grad_norm: 4.556e-02, pde_res: 1.247e-01, time: 1.096e-02\n",
      "epoch: 1800, loss: 1.330e-01, grad_norm: 6.323e-02, pde_res: 1.330e-01, time: 1.264e-02\n",
      "epoch: 1900, loss: 1.221e-01, grad_norm: 1.060e-01, pde_res: 1.219e-01, time: 1.233e-02\n",
      "epoch: 2000, loss: 1.235e-01, grad_norm: 2.347e-01, pde_res: 1.235e-01, time: 1.186e-02\n",
      "epoch: 2100, loss: 1.245e-01, grad_norm: 1.606e-01, pde_res: 1.245e-01, time: 1.195e-02\n",
      "epoch: 2200, loss: 1.224e-01, grad_norm: 6.469e-02, pde_res: 1.223e-01, time: 1.264e-02\n",
      "epoch: 2300, loss: 1.190e-01, grad_norm: 2.036e-01, pde_res: 1.187e-01, time: 1.098e-02\n",
      "epoch: 2400, loss: 1.287e-01, grad_norm: 7.351e-02, pde_res: 1.286e-01, time: 1.038e-02\n",
      "epoch: 2500, loss: 1.209e-01, grad_norm: 3.346e-01, pde_res: 1.208e-01, time: 1.127e-02\n",
      "epoch: 2600, loss: 1.315e-01, grad_norm: 2.428e-01, pde_res: 1.314e-01, time: 1.167e-02\n",
      "epoch: 2700, loss: 1.182e-01, grad_norm: 1.692e-01, pde_res: 1.182e-01, time: 1.097e-02\n",
      "epoch: 2800, loss: 1.167e-01, grad_norm: 5.278e-01, pde_res: 1.167e-01, time: 1.158e-02\n",
      "epoch: 2900, loss: 1.266e-01, grad_norm: 1.368e-01, pde_res: 1.265e-01, time: 1.117e-02\n",
      "epoch: 3000, loss: 1.215e-01, grad_norm: 8.887e-02, pde_res: 1.215e-01, time: 1.116e-02\n",
      "epoch: 3100, loss: 1.205e-01, grad_norm: 6.670e-01, pde_res: 1.205e-01, time: 1.154e-02\n",
      "epoch: 3200, loss: 1.265e-01, grad_norm: 2.038e-01, pde_res: 1.264e-01, time: 1.034e-02\n",
      "epoch: 3300, loss: 1.340e-01, grad_norm: 2.020e-01, pde_res: 1.339e-01, time: 1.159e-02\n",
      "epoch: 3400, loss: 1.238e-01, grad_norm: 5.048e-01, pde_res: 1.235e-01, time: 1.103e-02\n",
      "epoch: 3500, loss: 1.204e-01, grad_norm: 2.536e-01, pde_res: 1.204e-01, time: 1.154e-02\n",
      "epoch: 3600, loss: 1.195e-01, grad_norm: 1.647e-01, pde_res: 1.195e-01, time: 1.153e-02\n",
      "epoch: 3700, loss: 1.189e-01, grad_norm: 1.237e-01, pde_res: 1.189e-01, time: 1.084e-02\n",
      "epoch: 3800, loss: 1.306e-01, grad_norm: 2.317e-01, pde_res: 1.306e-01, time: 1.257e-02\n",
      "epoch: 3900, loss: 1.227e-01, grad_norm: 1.091e-01, pde_res: 1.226e-01, time: 1.111e-02\n",
      "epoch: 4000, loss: 1.169e-01, grad_norm: 7.759e-02, pde_res: 1.168e-01, time: 1.167e-02\n",
      "epoch: 4100, loss: 1.192e-01, grad_norm: 2.603e-01, pde_res: 1.191e-01, time: 1.193e-02\n",
      "epoch: 4200, loss: 1.233e-01, grad_norm: 3.741e-01, pde_res: 1.231e-01, time: 1.094e-02\n",
      "epoch: 4300, loss: 1.214e-01, grad_norm: 3.803e-01, pde_res: 1.213e-01, time: 1.092e-02\n",
      "epoch: 4400, loss: 1.200e-01, grad_norm: 1.817e-01, pde_res: 1.200e-01, time: 1.130e-02\n",
      "epoch: 4500, loss: 1.138e-01, grad_norm: 9.858e-02, pde_res: 1.138e-01, time: 1.106e-02\n",
      "epoch: 4600, loss: 1.210e-01, grad_norm: 2.750e-01, pde_res: 1.209e-01, time: 1.041e-02\n",
      "epoch: 4700, loss: 1.197e-01, grad_norm: 1.441e-01, pde_res: 1.196e-01, time: 1.022e-02\n",
      "epoch: 4800, loss: 1.125e-01, grad_norm: 4.493e-01, pde_res: 1.125e-01, time: 1.158e-02\n",
      "epoch: 4900, loss: 1.117e-01, grad_norm: 6.891e-02, pde_res: 1.116e-01, time: 1.070e-02\n",
      "epoch: 5000, loss: 1.163e-01, grad_norm: 1.497e-01, pde_res: 1.162e-01, time: 1.092e-02\n",
      "epoch: 5100, loss: 1.122e-01, grad_norm: 2.022e-01, pde_res: 1.122e-01, time: 1.074e-02\n",
      "epoch: 5200, loss: 1.201e-01, grad_norm: 2.076e-01, pde_res: 1.201e-01, time: 1.073e-02\n",
      "epoch: 5300, loss: 1.154e-01, grad_norm: 1.132e-01, pde_res: 1.154e-01, time: 1.076e-02\n",
      "epoch: 5400, loss: 1.105e-01, grad_norm: 1.862e-01, pde_res: 1.105e-01, time: 1.083e-02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m grad_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnet\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[1;32m---> 46\u001b[0m     grad_norm \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     47\u001b[0m grad_norm \u001b[38;5;241m=\u001b[39m grad_norm\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m<\u001b[39m best_loss:\n",
      "File \u001b[1;32mc:\\Users\\andyh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:647\u001b[0m, in \u001b[0;36mTensor.norm\u001b[1;34m(self, p, dim, keepdim, dtype)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    645\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mnorm, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, p\u001b[38;5;241m=\u001b[39mp, dim\u001b[38;5;241m=\u001b[39mdim, keepdim\u001b[38;5;241m=\u001b[39mkeepdim, dtype\u001b[38;5;241m=\u001b[39mdtype\n\u001b[0;32m    646\u001b[0m     )\n\u001b[1;32m--> 647\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\andyh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\functional.py:1517\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[0;32m   1515\u001b[0m _p \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m p\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvector_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mvector_norm(\u001b[38;5;28minput\u001b[39m, _p, _dim, keepdim, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n= int(5e3)\n",
    "# n=1\n",
    "sn = int(5e3)\n",
    "best_loss = np.inf\n",
    "max_epochs = int(2e4)\n",
    "print_freq = 100\n",
    "\n",
    "sampling_freq = 10 # how often to resample collocation and source points\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    start_time = time.time()\n",
    "    if epoch % sampling_freq == 0:\n",
    "        # points for source PDE loss. uvpoints are wind field at different times. source_values is the value of source at source_colloc_points (assumes Gaussian for now)\n",
    "        source_collocation_points = model.source_points(sn,2*sigma) \n",
    "        # source_uv_points = torch.ones(len(source_collocation_points),2)*.5\n",
    "        # initial condition collocation points with smaller time values 0.1*t_final. \n",
    "        # ic_col = torch.cat([torch.rand(sn,1)*tfinal*.1, torch.rand(sn,1)*x_max, torch.rand(sn,1)*y_max, torch.rand(sn,1)*z_max], dim=1)\n",
    "        collocation_points = torch.cat([torch.rand(n,1)*tfinal, torch.rand(n,1)*x_max*2 - x_max/2, torch.rand(n,1)*y_max*2 - y_max/2, torch.rand(n,1)*z_max*2-z_max/2], dim=1)\n",
    "        # collocation_points = torch.cat([collocation_points,ic_col,source_collocation_points])\n",
    "        collocation_points = torch.cat([collocation_points,source_collocation_points])\n",
    "        collocation_points.requires_grad_(True)\n",
    "        # collocation_points.requires_grad=True\n",
    "        uv = torch.zeros(len(collocation_points),2)*.1#wind tensor\n",
    "        # print(collocation_points[-2])\n",
    "        uv[:,1:]=-1\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss_1 ,pde_1 = model.compute_pde_loss(collocation_points,uv) # PDE residual loss\n",
    "    loss_2 = model.compute_negative_loss(collocation_points)\n",
    "    # loss_2,pde_2 = model.loss_function(source_collocation_points, source_uv_points) # source term PDE residual loss \n",
    "    # loss_3 ,pde_3 = model.loss_function(torch.concat([collocation_points,source_collocation_points]),torch.concat([collocation_points,source_collocation_points]))\n",
    "\n",
    "    # loss = loss_1 + loss_2\n",
    "    # loss = loss_2*100\n",
    "    loss = loss_1+loss_2*100\n",
    "\n",
    "    # # print loss at first epoch\n",
    "    # if epoch == 0:\n",
    "    #     print('epoch: %d, loss: %1.3e, pde_res: %1.3e, source_loss: %1.3e' % (epoch, loss.item(), loss_1.item(), loss_2.item()))\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # compute norm of gradient of the network\n",
    "    grad_norm = 0\n",
    "    for p in model.net.parameters():\n",
    "        grad_norm += p.grad.data.norm(2).item()**2\n",
    "    grad_norm = grad_norm**0.5\n",
    "\n",
    "\n",
    "    if loss.item() < best_loss:\n",
    "        torch.save(model,'best_mod.m')\n",
    "    optimizer.step()\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    # scheduler.step()\n",
    "\n",
    "    if epoch % print_freq == 0:\n",
    "\n",
    "        # print epoch and loss using %1.3e format\n",
    "        # print('epoch: %d, loss: %1.3e, grad_norm: %1.3e, pde_res: %1.3e, source_loss: %1.3e, time: %1.3e' % (epoch, loss.item(), grad_norm, loss_1.item(), loss_2.item(), epoch_time))\n",
    "        print('epoch: %d, loss: %1.3e, grad_norm: %1.3e, pde_res: %1.3e, time: %1.3e' % (epoch, loss.item(), grad_norm, loss_1.item(), epoch_time))\n",
    "\n",
    "        # print(epoch, loss.item())\n",
    "        # print(loss_2.item(),loss_1.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0932,  0.0262,  0.0416, -0.0281],\n",
       "        [ 2.0336, -0.0442, -0.0054,  0.0558],\n",
       "        [ 3.7279,  0.0332, -0.0206, -0.0660],\n",
       "        ...,\n",
       "        [ 3.3965,  1.0041,  0.9177,  0.9794],\n",
       "        [ 1.4611,  1.1220,  1.0279,  0.9961],\n",
       "        [ 3.5538,  1.0502,  0.9799,  1.0316]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_collocation_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL PINN.PINN was not an allowed global by default. Please use `torch.serialization.add_safe_globals([PINN])` or the `torch.serialization.safe_globals([PINN])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_mod.m\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\serialization.py:1470\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1462\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[0;32m   1463\u001b[0m                     opened_zipfile,\n\u001b[0;32m   1464\u001b[0m                     map_location,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1467\u001b[0m                     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[0;32m   1468\u001b[0m                 )\n\u001b[0;32m   1469\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1470\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1471\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[0;32m   1472\u001b[0m             opened_zipfile,\n\u001b[0;32m   1473\u001b[0m             map_location,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1476\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[0;32m   1477\u001b[0m         )\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL PINN.PINN was not an allowed global by default. Please use `torch.serialization.add_safe_globals([PINN])` or the `torch.serialization.safe_globals([PINN])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "source": [
    "model = torch.load('best_mod.m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Plot the concentration over time\\nfor t in time_steps:\\n    t_tensor = torch.full((grid_points.shape[0], 1), t, dtype=torch.float32)  # Time input\\n    concentration = net(grid_points, t_tensor).cpu().detach().numpy().reshape(100, 100)  # Predict and reshape\\n    \\n    plt.figure()\\n    plt.contourf(X, Y, concentration, levels=50, cmap=\\'viridis\\', vmin=0, vmax=10)  # Plot concentration as a contour plot\\n    plt.plot(source_loc[0,0].cpu(), source_loc[0,1].cpu(), \\'ro\\', label=\\'Source Location\\')  # Plot the source location\\n    plt.colorbar(label=\\'Concentration\\')\\n    # fix colorbar from 0 to 1 \\n    # plt.clim(0, 10.0)  # Set colorbar limits\\n    plt.title(f\"Gas Concentration at t = {t:.2f}\")\\n    plt.xlabel(\\'x\\')\\n    plt.ylabel(\\'y\\')\\n    # fix colorbar \\n    # plt.savefig(f\"concentration_t_{t:.2f}.png\")  # Save the plot as an image\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load the best model \n",
    "Z_value = .5\n",
    "# net.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Define the grid and time steps\n",
    "n= 100\n",
    "x_grid = np.linspace(0, x_max, n)\n",
    "y_grid = np.linspace(0, y_max, n)\n",
    "z_grid = np.linspace(0, z_max, n)\n",
    "\n",
    "X, Y, = np.meshgrid(x_grid, y_grid)\n",
    "Z= X * 0 + Z_value\n",
    "\n",
    "grid_points = np.vstack([X.ravel(), Y.ravel(), Z.ravel()]).T\n",
    "# grid_points = np.vstack([X.ravel(), Y.ravel(), Z.ravel()]).T  # Flatten the grid\n",
    "grid_points = torch.tensor(grid_points, dtype=torch.float32)\n",
    "\n",
    "time_steps = np.linspace(0, tfinal, 20)  # 10 time steps from 0 to 1\n",
    "\n",
    "\n",
    "'''\n",
    "# Plot the concentration over time\n",
    "for t in time_steps:\n",
    "    t_tensor = torch.full((grid_points.shape[0], 1), t, dtype=torch.float32)  # Time input\n",
    "    concentration = net(grid_points, t_tensor).cpu().detach().numpy().reshape(100, 100)  # Predict and reshape\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.contourf(X, Y, concentration, levels=50, cmap='viridis', vmin=0, vmax=10)  # Plot concentration as a contour plot\n",
    "    plt.plot(source_loc[0,0].cpu(), source_loc[0,1].cpu(), 'ro', label='Source Location')  # Plot the source location\n",
    "    plt.colorbar(label='Concentration')\n",
    "    # fix colorbar from 0 to 1 \n",
    "    # plt.clim(0, 10.0)  # Set colorbar limits\n",
    "    plt.title(f\"Gas Concentration at t = {t:.2f}\")\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    # fix colorbar \n",
    "    # plt.savefig(f\"concentration_t_{t:.2f}.png\")  # Save the plot as an image\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andyh\\AppData\\Local\\Temp\\ipykernel_5476\\498029673.py:24: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images.append(imageio.imread(f\"concentration_t_{t:.2f}.png\"))  # Append the image to the list\n"
     ]
    }
   ],
   "source": [
    "# save as a GIF\n",
    "import imageio\n",
    "import os\n",
    "\n",
    "images = []\n",
    "# source_loc = torch.tensor([[.5,.5,.5]])\n",
    "source_loc = model.source_locs\n",
    "for t in time_steps:\n",
    "    t_tensor = torch.full((grid_points.shape[0], 1), t, dtype=torch.float32)  # Time input\n",
    "    concentration = model.forward(torch.cat([t_tensor,grid_points],dim=1),scaled=True).cpu().detach().numpy().reshape(100, 100)  # Predict and reshape\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.contourf(X, Y, concentration, levels=50, cmap='viridis', vmin=0, vmax=.5)  # Plot concentration as a contour plot\n",
    "    plt.plot(model.source_locs[1,0], model.source_locs[1,1], 'ro', label='Source Location')  # Plot the source location\n",
    "    plt.plot(model.source_locs[0,0], model.source_locs[0,1], 'ro', label='Source Location')  # Plot the source location\n",
    "\n",
    "    plt.colorbar(label='Concentration')\n",
    "    plt.title(f\"Gas Concentration at t = {t:.2f}\")\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.savefig(f\"concentration_t_{t:.2f}.png\")  # Save the plot as an image\n",
    "    plt.close()\n",
    "    \n",
    "    images.append(imageio.imread(f\"concentration_t_{t:.2f}.png\"))  # Append the image to the list\n",
    "    os.remove(f\"concentration_t_{t:.2f}.png\")  # Remove the image file\n",
    "\n",
    "imageio.mimsave(f'test_visual_basic.gif', images)  # Save the images as a GIF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model.net.hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(source_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
