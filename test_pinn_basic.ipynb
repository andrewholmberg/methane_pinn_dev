{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import imageio\n",
    "from PINN import PINN\n",
    "from Net import Net\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import sklearn.mixture as mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"{os.getcwd()}/pinn_test_data\"\n",
    "# load in data\n",
    "df_wind_ch4 = pd.read_csv(data_dir + \"/wind_ch4.csv\")\n",
    "df_true_emission = pd.read_csv(data_dir + \"/selected_controll_release.csv\")\n",
    "source_points = np.load(data_dir + \"/source_points.npy\") # shape=(n_source, 3)\n",
    "sensor_points = np.load(data_dir + \"/sensor_points.npy\") # shape=(n_sensor, 3)\n",
    "#col_points = np.load(data_dir + \"/col_points.npy\")  # shape=(n_col, 3)\n",
    "df_bounds = pd.read_csv(data_dir + \"/bounds.csv\", dtype='float32')\n",
    "x_min = df_bounds['x_min'][0]\n",
    "x_max = df_bounds['x_max'][0]\n",
    "y_min = df_bounds['y_min'][0]\n",
    "y_max = df_bounds['y_max'][0]\n",
    "z_min = df_bounds['z_min'][0]\n",
    "z_max = df_bounds['z_max'][0]\n",
    "\n",
    "x_max = 1\n",
    "y_max = 1\n",
    "z_max = 1\n",
    "tfinal = 1.\n",
    "source_location = np.array([[.5,.5,.5]])\n",
    "\n",
    "ws = df_wind_ch4['wind_speed.m/s'].to_numpy() # shape=(N_t,)\n",
    "wd = df_wind_ch4['wind_direction'].to_numpy() # shape=(N_t,)\n",
    "ch4 = np.transpose(df_wind_ch4.iloc[:, 3:].to_numpy()) # shape=(N_obs, N_t)\n",
    "sensor_names = df_wind_ch4.columns[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma=.025\n",
    "model = PINN([50,50,50])\n",
    "model.set_location(source_location,[tfinal,x_max,y_max,z_max],source_values=[1],sigma=sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.net.parameters(), lr=1e-3)\n",
    "# from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "# scheduler = ExponentialLR(optimizer, gamma=0.999)  # Decay LR by 5% every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 2.367e+01, grad_norm: 1.289e+01, pde_res: 2.367e+01, time: 3.945e-01\n",
      "epoch: 100, loss: 1.729e+01, grad_norm: 2.265e+00, pde_res: 1.729e+01, time: 2.375e-02\n",
      "epoch: 200, loss: 9.663e+00, grad_norm: 3.991e+00, pde_res: 9.663e+00, time: 2.412e-02\n",
      "epoch: 300, loss: 6.742e+00, grad_norm: 5.168e+00, pde_res: 6.742e+00, time: 2.380e-02\n",
      "epoch: 400, loss: 5.259e+00, grad_norm: 4.511e+00, pde_res: 5.259e+00, time: 2.383e-02\n",
      "epoch: 500, loss: 4.408e+00, grad_norm: 1.116e+01, pde_res: 4.408e+00, time: 2.393e-02\n",
      "epoch: 600, loss: 3.662e+00, grad_norm: 1.136e+01, pde_res: 3.662e+00, time: 2.379e-02\n",
      "epoch: 700, loss: 2.647e+00, grad_norm: 5.560e+00, pde_res: 2.647e+00, time: 2.390e-02\n",
      "epoch: 800, loss: 2.176e+00, grad_norm: 3.564e+00, pde_res: 2.176e+00, time: 2.406e-02\n",
      "epoch: 900, loss: 1.820e+00, grad_norm: 2.858e+00, pde_res: 1.820e+00, time: 2.509e-02\n",
      "epoch: 1000, loss: 1.642e+00, grad_norm: 7.504e+00, pde_res: 1.642e+00, time: 2.444e-02\n",
      "epoch: 1100, loss: 1.482e+00, grad_norm: 4.007e+00, pde_res: 1.482e+00, time: 2.362e-02\n",
      "epoch: 1200, loss: 1.319e+00, grad_norm: 2.324e+00, pde_res: 1.319e+00, time: 2.390e-02\n",
      "epoch: 1300, loss: 1.235e+00, grad_norm: 3.226e+00, pde_res: 1.235e+00, time: 2.361e-02\n",
      "epoch: 1400, loss: 1.140e+00, grad_norm: 8.533e+00, pde_res: 1.140e+00, time: 2.287e-02\n",
      "epoch: 1500, loss: 1.045e+00, grad_norm: 4.995e+00, pde_res: 1.045e+00, time: 2.299e-02\n",
      "epoch: 1600, loss: 9.926e-01, grad_norm: 5.122e+00, pde_res: 9.926e-01, time: 2.451e-02\n",
      "epoch: 1700, loss: 9.002e-01, grad_norm: 2.557e+00, pde_res: 9.002e-01, time: 2.389e-02\n",
      "epoch: 1800, loss: 9.090e-01, grad_norm: 3.604e+00, pde_res: 9.090e-01, time: 2.331e-02\n",
      "epoch: 1900, loss: 8.311e-01, grad_norm: 2.073e+00, pde_res: 8.311e-01, time: 2.323e-02\n",
      "epoch: 2000, loss: 8.211e-01, grad_norm: 3.985e+00, pde_res: 8.211e-01, time: 2.330e-02\n",
      "epoch: 2100, loss: 7.644e-01, grad_norm: 2.842e+00, pde_res: 7.644e-01, time: 2.411e-02\n",
      "epoch: 2200, loss: 7.018e-01, grad_norm: 4.317e+00, pde_res: 7.018e-01, time: 2.332e-02\n",
      "epoch: 2300, loss: 6.931e-01, grad_norm: 1.688e+00, pde_res: 6.931e-01, time: 2.368e-02\n",
      "epoch: 2400, loss: 7.043e-01, grad_norm: 3.419e+00, pde_res: 7.043e-01, time: 2.304e-02\n",
      "epoch: 2500, loss: 6.900e-01, grad_norm: 3.694e+00, pde_res: 6.900e-01, time: 2.362e-02\n",
      "epoch: 2600, loss: 6.882e-01, grad_norm: 2.366e+00, pde_res: 6.882e-01, time: 2.376e-02\n",
      "epoch: 2700, loss: 6.359e-01, grad_norm: 3.551e+00, pde_res: 6.359e-01, time: 2.486e-02\n",
      "epoch: 2800, loss: 6.470e-01, grad_norm: 3.285e+00, pde_res: 6.470e-01, time: 2.433e-02\n",
      "epoch: 2900, loss: 5.751e-01, grad_norm: 1.696e+00, pde_res: 5.751e-01, time: 2.399e-02\n",
      "epoch: 3000, loss: 5.916e-01, grad_norm: 3.515e+00, pde_res: 5.916e-01, time: 2.399e-02\n",
      "epoch: 3100, loss: 5.932e-01, grad_norm: 1.893e+00, pde_res: 5.932e-01, time: 2.229e-02\n",
      "epoch: 3200, loss: 5.770e-01, grad_norm: 3.120e+00, pde_res: 5.770e-01, time: 2.426e-02\n",
      "epoch: 3300, loss: 5.461e-01, grad_norm: 5.336e+00, pde_res: 5.461e-01, time: 2.425e-02\n",
      "epoch: 3400, loss: 5.842e-01, grad_norm: 2.456e+00, pde_res: 5.842e-01, time: 2.363e-02\n",
      "epoch: 3500, loss: 5.874e-01, grad_norm: 2.345e+00, pde_res: 5.874e-01, time: 2.483e-02\n",
      "epoch: 3600, loss: 5.077e-01, grad_norm: 4.746e+00, pde_res: 5.077e-01, time: 2.425e-02\n",
      "epoch: 3700, loss: 5.485e-01, grad_norm: 1.421e+00, pde_res: 5.485e-01, time: 2.388e-02\n",
      "epoch: 3800, loss: 5.078e-01, grad_norm: 2.307e+00, pde_res: 5.078e-01, time: 2.277e-02\n",
      "epoch: 3900, loss: 5.381e-01, grad_norm: 3.350e+00, pde_res: 5.381e-01, time: 2.445e-02\n",
      "epoch: 4000, loss: 4.950e-01, grad_norm: 2.900e+00, pde_res: 4.950e-01, time: 2.374e-02\n",
      "epoch: 4100, loss: 4.599e-01, grad_norm: 4.046e+00, pde_res: 4.599e-01, time: 2.336e-02\n",
      "epoch: 4200, loss: 4.951e-01, grad_norm: 4.173e+00, pde_res: 4.951e-01, time: 2.387e-02\n",
      "epoch: 4300, loss: 4.740e-01, grad_norm: 1.899e+00, pde_res: 4.740e-01, time: 2.377e-02\n",
      "epoch: 4400, loss: 4.200e-01, grad_norm: 1.161e+00, pde_res: 4.200e-01, time: 2.395e-02\n",
      "epoch: 4500, loss: 4.455e-01, grad_norm: 4.558e+00, pde_res: 4.455e-01, time: 2.321e-02\n",
      "epoch: 4600, loss: 4.574e-01, grad_norm: 5.884e+00, pde_res: 4.574e-01, time: 2.483e-02\n",
      "epoch: 4700, loss: 4.454e-01, grad_norm: 6.308e+00, pde_res: 4.454e-01, time: 2.379e-02\n",
      "epoch: 4800, loss: 4.318e-01, grad_norm: 2.886e+00, pde_res: 4.318e-01, time: 2.489e-02\n",
      "epoch: 4900, loss: 4.460e-01, grad_norm: 1.519e+00, pde_res: 4.460e-01, time: 2.380e-02\n"
     ]
    }
   ],
   "source": [
    "n= int(5e3)\n",
    "sn = 500\n",
    "best_loss = np.inf\n",
    "max_epochs = int(5e3)\n",
    "print_freq = 100\n",
    "\n",
    "sampling_freq = 10 # how often to resample collocation and source points\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if epoch % sampling_freq == 0:\n",
    "        # points for source PDE loss. uvpoints are wind field at different times. source_values is the value of source at source_colloc_points (assumes Gaussian for now)\n",
    "        source_collocation_points = model.source_points(sn,sigma) \n",
    "        # source_uv_points = torch.ones(len(source_collocation_points),2)*.5\n",
    "        # initial condition collocation points with smaller time values 0.1*t_final. \n",
    "        ic_col = torch.cat([torch.rand(sn,1)*tfinal*.1, torch.rand(sn,1)*x_max, torch.rand(sn,1)*y_max, torch.rand(sn,1)*z_max], dim=1)\n",
    "        collocation_points = torch.cat([torch.rand(n,1)*tfinal, torch.rand(n,1)*x_max, torch.rand(n,1)*y_max, torch.rand(n,1)*z_max*1.5], dim=1)\n",
    "        collocation_points = torch.cat([collocation_points,ic_col,source_collocation_points])\n",
    "        # collocation_points.requires_grad=True\n",
    "        uv = torch.ones(len(collocation_points),2)*1 #wind tensor\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss_1 ,pde_1 = model.loss_function(collocation_points,uv) # PDE residual loss\n",
    "    # loss_2,pde_2 = model.loss_function(source_collocation_points, source_uv_points) # source term PDE residual loss \n",
    "    # loss_3 ,pde_3 = model.loss_function(torch.concat([collocation_points,source_collocation_points]),torch.concat([collocation_points,source_collocation_points]))\n",
    "\n",
    "    # loss = loss_1 + loss_2\n",
    "    # loss = loss_2*100\n",
    "    loss = loss_1\n",
    "\n",
    "    # # print loss at first epoch\n",
    "    # if epoch == 0:\n",
    "    #     print('epoch: %d, loss: %1.3e, pde_res: %1.3e, source_loss: %1.3e' % (epoch, loss.item(), loss_1.item(), loss_2.item()))\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # compute norm of gradient of the network\n",
    "    grad_norm = 0\n",
    "    for p in model.net.parameters():\n",
    "        grad_norm += p.grad.data.norm(2).item()**2\n",
    "    grad_norm = grad_norm**0.5\n",
    "\n",
    "\n",
    "    if loss.item() < best_loss:\n",
    "        torch.save(model,'best_mod.m')\n",
    "    optimizer.step()\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    # scheduler.step()\n",
    "\n",
    "    if epoch % print_freq == 0:\n",
    "\n",
    "        # print epoch and loss using %1.3e format\n",
    "        # print('epoch: %d, loss: %1.3e, grad_norm: %1.3e, pde_res: %1.3e, source_loss: %1.3e, time: %1.3e' % (epoch, loss.item(), grad_norm, loss_1.item(), loss_2.item(), epoch_time))\n",
    "        print('epoch: %d, loss: %1.3e, grad_norm: %1.3e, pde_res: %1.3e, time: %1.3e' % (epoch, loss.item(), grad_norm, loss_1.item(), epoch_time))\n",
    "\n",
    "        # print(epoch, loss.item())\n",
    "        # print(loss_2.item(),loss_1.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(x_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('best_mod.m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Plot the concentration over time\\nfor t in time_steps:\\n    t_tensor = torch.full((grid_points.shape[0], 1), t, dtype=torch.float32)  # Time input\\n    concentration = net(grid_points, t_tensor).cpu().detach().numpy().reshape(100, 100)  # Predict and reshape\\n    \\n    plt.figure()\\n    plt.contourf(X, Y, concentration, levels=50, cmap=\\'viridis\\', vmin=0, vmax=10)  # Plot concentration as a contour plot\\n    plt.plot(source_loc[0,0].cpu(), source_loc[0,1].cpu(), \\'ro\\', label=\\'Source Location\\')  # Plot the source location\\n    plt.colorbar(label=\\'Concentration\\')\\n    # fix colorbar from 0 to 1 \\n    # plt.clim(0, 10.0)  # Set colorbar limits\\n    plt.title(f\"Gas Concentration at t = {t:.2f}\")\\n    plt.xlabel(\\'x\\')\\n    plt.ylabel(\\'y\\')\\n    # fix colorbar \\n    # plt.savefig(f\"concentration_t_{t:.2f}.png\")  # Save the plot as an image\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load the best model \n",
    "Z_value = .5\n",
    "# net.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Define the grid and time steps\n",
    "n= 100\n",
    "x_grid = np.linspace(0, x_max, n)\n",
    "y_grid = np.linspace(0, y_max, n)\n",
    "z_grid = np.linspace(0, z_max, n)\n",
    "\n",
    "X, Y, = np.meshgrid(x_grid, y_grid)\n",
    "Z= X * 0 + Z_value\n",
    "\n",
    "grid_points = np.vstack([X.ravel(), Y.ravel(), Z.ravel()]).T\n",
    "# grid_points = np.vstack([X.ravel(), Y.ravel(), Z.ravel()]).T  # Flatten the grid\n",
    "grid_points = torch.tensor(grid_points, dtype=torch.float32)\n",
    "\n",
    "time_steps = np.linspace(0, tfinal, 20)  # 10 time steps from 0 to 1\n",
    "\n",
    "\n",
    "'''\n",
    "# Plot the concentration over time\n",
    "for t in time_steps:\n",
    "    t_tensor = torch.full((grid_points.shape[0], 1), t, dtype=torch.float32)  # Time input\n",
    "    concentration = net(grid_points, t_tensor).cpu().detach().numpy().reshape(100, 100)  # Predict and reshape\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.contourf(X, Y, concentration, levels=50, cmap='viridis', vmin=0, vmax=10)  # Plot concentration as a contour plot\n",
    "    plt.plot(source_loc[0,0].cpu(), source_loc[0,1].cpu(), 'ro', label='Source Location')  # Plot the source location\n",
    "    plt.colorbar(label='Concentration')\n",
    "    # fix colorbar from 0 to 1 \n",
    "    # plt.clim(0, 10.0)  # Set colorbar limits\n",
    "    plt.title(f\"Gas Concentration at t = {t:.2f}\")\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    # fix colorbar \n",
    "    # plt.savefig(f\"concentration_t_{t:.2f}.png\")  # Save the plot as an image\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andyh\\AppData\\Local\\Temp\\ipykernel_13140\\365763053.py:22: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images.append(imageio.imread(f\"concentration_t_{t:.2f}.png\"))  # Append the image to the list\n"
     ]
    }
   ],
   "source": [
    "# save as a GIF\n",
    "import imageio\n",
    "import os\n",
    "\n",
    "images = []\n",
    "# source_loc = torch.tensor([[.5,.5,.5]])\n",
    "source_loc = model.source_locs\n",
    "for t in time_steps:\n",
    "    t_tensor = torch.full((grid_points.shape[0], 1), t, dtype=torch.float32)  # Time input\n",
    "    concentration = model.forward(torch.cat([t_tensor,grid_points],dim=1),scaled=True).cpu().detach().numpy().reshape(100, 100)  # Predict and reshape\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.contourf(X, Y, concentration, levels=50, cmap='viridis', vmin=0, vmax=10)  # Plot concentration as a contour plot\n",
    "    plt.plot(model.source_locs[0,0], model.source_locs[0,1], 'ro', label='Source Location')  # Plot the source location\n",
    "    plt.colorbar(label='Concentration')\n",
    "    plt.title(f\"Gas Concentration at t = {t:.2f}\")\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.savefig(f\"concentration_t_{t:.2f}.png\")  # Save the plot as an image\n",
    "    plt.close()\n",
    "    \n",
    "    images.append(imageio.imread(f\"concentration_t_{t:.2f}.png\"))  # Append the image to the list\n",
    "    os.remove(f\"concentration_t_{t:.2f}.png\")  # Remove the image file\n",
    "\n",
    "imageio.mimsave(f'test_visual.gif', images)  # Save the images as a GIF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(model.net.hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[61.84826691 40.32822479  4.5       ]\n",
      " [99.10094831 54.69940709  2.        ]\n",
      " [99.89962676 24.72759871  2.        ]\n",
      " [23.54499552 57.03946784  2.        ]\n",
      " [25.09781584 22.62636785  2.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(source_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'source_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43msource_values\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'source_values' is not defined"
     ]
    }
   ],
   "source": [
    "print(source_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
